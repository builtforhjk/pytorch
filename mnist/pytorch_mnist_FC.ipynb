{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from FileReader import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_mnist('train')\n",
    "train_imgs = torch.from_numpy(train_set['images']).type(torch.float)\n",
    "train_labels = torch.from_numpy(train_set['labels']).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本参数\n",
    "train_imgs_num = train_imgs.shape[0]\n",
    "BATCH_SIZE = int(train_imgs_num * 0.05)\n",
    "use_dropout = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理(拉伸，零均值化)\n",
    "train_vec_imgs = train_imgs.reshape(train_imgs_num, -1)\n",
    "train_vec_imgs -= torch.mean(train_vec_imgs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourLayersNet(nn.Module):\n",
    "    '''\n",
    "    三层全连接网络进行mnist分类\n",
    "    ReLU激励\n",
    "    '''\n",
    "    def __init__(self, n_feature, n_output, *vargs):\n",
    "        super(FourLayersNet, self).__init__()\n",
    "        if len(vargs) == 0:\n",
    "            self.layers1 = nn.Linear(n_feature, 300)\n",
    "            self.layers2 = nn.Linear(300, 100)\n",
    "            self.layers3 = nn.Linear(100, 10)\n",
    "        else:\n",
    "            # todo: xxx\n",
    "            pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 第一层输出\n",
    "        h1 = self.layers1(x)\n",
    "        a1 = F.relu(h1)\n",
    "        \n",
    "        #第二层输出\n",
    "        h2 = self.layers2(a1)\n",
    "        a2 = F.relu(h2)\n",
    "        \n",
    "        #输出层输出\n",
    "        h3 = self.layers3(a2)\n",
    "        \n",
    "        return h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FourLayersNet(n_feature=784, n_output=10)\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批处理\n",
    "torch_dataset = Data.TensorDataset(train_vec_imgs,train_labels)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# for step, (batch_imgs, batch_labels) in enumerate(loader):\n",
    "#     print 'step {}: '.format(step+1)\n",
    "#     print batch_imgs.shape\n",
    "#     print batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | batch 1 loss: 8.31102561951\n",
      "epoch 1 | batch 2 loss: 4.64883327484\n",
      "epoch 1 | batch 3 loss: 2.42849063873\n",
      "epoch 1 | batch 4 loss: 1.58929121494\n",
      "epoch 1 | batch 5 loss: 1.3609610796\n",
      "epoch 1 | batch 6 loss: 1.20207250118\n",
      "epoch 1 | batch 7 loss: 0.996592760086\n",
      "epoch 1 | batch 8 loss: 0.972966253757\n",
      "epoch 1 | batch 9 loss: 0.933719754219\n",
      "epoch 1 | batch 10 loss: 0.70191681385\n",
      "epoch 1 | batch 11 loss: 0.556003153324\n",
      "epoch 1 | batch 12 loss: 0.658551454544\n",
      "epoch 1 | batch 13 loss: 0.620850801468\n",
      "epoch 1 | batch 14 loss: 0.55620354414\n",
      "epoch 1 | batch 15 loss: 0.592419803143\n",
      "epoch 1 | batch 16 loss: 0.467078238726\n",
      "epoch 1 | batch 17 loss: 0.379297941923\n",
      "epoch 1 | batch 18 loss: 0.444414645433\n",
      "epoch 1 | batch 19 loss: 0.424038946629\n",
      "epoch 1 | batch 20 loss: 0.428944587708\n",
      "epoch 2 | batch 1 loss: 0.390865713358\n",
      "epoch 2 | batch 2 loss: 0.360856890678\n",
      "epoch 2 | batch 3 loss: 0.335651516914\n",
      "epoch 2 | batch 4 loss: 0.33077287674\n",
      "epoch 2 | batch 5 loss: 0.323341012001\n",
      "epoch 2 | batch 6 loss: 0.294329762459\n",
      "epoch 2 | batch 7 loss: 0.293776780367\n",
      "epoch 2 | batch 8 loss: 0.27598541975\n",
      "epoch 2 | batch 9 loss: 0.300707161427\n",
      "epoch 2 | batch 10 loss: 0.258752733469\n",
      "epoch 2 | batch 11 loss: 0.26839441061\n",
      "epoch 2 | batch 12 loss: 0.291588306427\n",
      "epoch 2 | batch 13 loss: 0.232458695769\n",
      "epoch 2 | batch 14 loss: 0.280678212643\n",
      "epoch 2 | batch 15 loss: 0.26511824131\n",
      "epoch 2 | batch 16 loss: 0.242643088102\n",
      "epoch 2 | batch 17 loss: 0.223464742303\n",
      "epoch 2 | batch 18 loss: 0.260104954243\n",
      "epoch 2 | batch 19 loss: 0.240830570459\n",
      "epoch 2 | batch 20 loss: 0.222286105156\n",
      "epoch 3 | batch 1 loss: 0.192715317011\n",
      "epoch 3 | batch 2 loss: 0.215487495065\n",
      "epoch 3 | batch 3 loss: 0.187786862254\n",
      "epoch 3 | batch 4 loss: 0.192144200206\n",
      "epoch 3 | batch 5 loss: 0.196385622025\n",
      "epoch 3 | batch 6 loss: 0.189746052027\n",
      "epoch 3 | batch 7 loss: 0.181696042418\n",
      "epoch 3 | batch 8 loss: 0.189571201801\n",
      "epoch 3 | batch 9 loss: 0.164753913879\n",
      "epoch 3 | batch 10 loss: 0.174826562405\n",
      "epoch 3 | batch 11 loss: 0.211683690548\n",
      "epoch 3 | batch 12 loss: 0.1775110811\n",
      "epoch 3 | batch 13 loss: 0.170491725206\n",
      "epoch 3 | batch 14 loss: 0.186448439956\n",
      "epoch 3 | batch 15 loss: 0.178220942616\n",
      "epoch 3 | batch 16 loss: 0.168359145522\n",
      "epoch 3 | batch 17 loss: 0.162131652236\n",
      "epoch 3 | batch 18 loss: 0.193897098303\n",
      "epoch 3 | batch 19 loss: 0.178166374564\n",
      "epoch 3 | batch 20 loss: 0.177098304033\n",
      "epoch 4 | batch 1 loss: 0.155881613493\n",
      "epoch 4 | batch 2 loss: 0.163810133934\n",
      "epoch 4 | batch 3 loss: 0.149564966559\n",
      "epoch 4 | batch 4 loss: 0.165315151215\n",
      "epoch 4 | batch 5 loss: 0.14296887815\n",
      "epoch 4 | batch 6 loss: 0.125312253833\n",
      "epoch 4 | batch 7 loss: 0.13412386179\n",
      "epoch 4 | batch 8 loss: 0.133158281446\n",
      "epoch 4 | batch 9 loss: 0.146843358874\n",
      "epoch 4 | batch 10 loss: 0.118731513619\n",
      "epoch 4 | batch 11 loss: 0.156491205096\n",
      "epoch 4 | batch 12 loss: 0.145888730884\n",
      "epoch 4 | batch 13 loss: 0.156426891685\n",
      "epoch 4 | batch 14 loss: 0.141676947474\n",
      "epoch 4 | batch 15 loss: 0.139014393091\n",
      "epoch 4 | batch 16 loss: 0.14243850112\n",
      "epoch 4 | batch 17 loss: 0.153124466538\n",
      "epoch 4 | batch 18 loss: 0.142282262444\n",
      "epoch 4 | batch 19 loss: 0.136694341898\n",
      "epoch 4 | batch 20 loss: 0.135929778218\n",
      "epoch 5 | batch 1 loss: 0.113699555397\n",
      "epoch 5 | batch 2 loss: 0.147374391556\n",
      "epoch 5 | batch 3 loss: 0.113180279732\n",
      "epoch 5 | batch 4 loss: 0.136077448726\n",
      "epoch 5 | batch 5 loss: 0.14046856761\n",
      "epoch 5 | batch 6 loss: 0.129740521312\n",
      "epoch 5 | batch 7 loss: 0.113326489925\n",
      "epoch 5 | batch 8 loss: 0.112692311406\n",
      "epoch 5 | batch 9 loss: 0.110590688884\n",
      "epoch 5 | batch 10 loss: 0.13313126564\n",
      "epoch 5 | batch 11 loss: 0.124895423651\n",
      "epoch 5 | batch 12 loss: 0.131468012929\n",
      "epoch 5 | batch 13 loss: 0.115620613098\n",
      "epoch 5 | batch 14 loss: 0.119280904531\n",
      "epoch 5 | batch 15 loss: 0.112490937114\n",
      "epoch 5 | batch 16 loss: 0.121466271579\n",
      "epoch 5 | batch 17 loss: 0.103999264538\n",
      "epoch 5 | batch 18 loss: 0.119874715805\n",
      "epoch 5 | batch 19 loss: 0.114660412073\n",
      "epoch 5 | batch 20 loss: 0.101075723767\n",
      "epoch 6 | batch 1 loss: 0.101694963872\n",
      "epoch 6 | batch 2 loss: 0.10917685926\n",
      "epoch 6 | batch 3 loss: 0.103214539587\n",
      "epoch 6 | batch 4 loss: 0.10471624881\n",
      "epoch 6 | batch 5 loss: 0.116676717997\n",
      "epoch 6 | batch 6 loss: 0.108348980546\n",
      "epoch 6 | batch 7 loss: 0.109512858093\n",
      "epoch 6 | batch 8 loss: 0.121297329664\n",
      "epoch 6 | batch 9 loss: 0.0819103866816\n",
      "epoch 6 | batch 10 loss: 0.100146882236\n",
      "epoch 6 | batch 11 loss: 0.104098774493\n",
      "epoch 6 | batch 12 loss: 0.0873864516616\n",
      "epoch 6 | batch 13 loss: 0.0990216657519\n",
      "epoch 6 | batch 14 loss: 0.112530983984\n",
      "epoch 6 | batch 15 loss: 0.0927239358425\n",
      "epoch 6 | batch 16 loss: 0.106443539262\n",
      "epoch 6 | batch 17 loss: 0.095988675952\n",
      "epoch 6 | batch 18 loss: 0.100447610021\n",
      "epoch 6 | batch 19 loss: 0.11246688664\n",
      "epoch 6 | batch 20 loss: 0.0983002409339\n",
      "epoch 7 | batch 1 loss: 0.101306721568\n",
      "epoch 7 | batch 2 loss: 0.089208483696\n",
      "epoch 7 | batch 3 loss: 0.0928803235292\n",
      "epoch 7 | batch 4 loss: 0.091532997787\n",
      "epoch 7 | batch 5 loss: 0.0781651362777\n",
      "epoch 7 | batch 6 loss: 0.118521884084\n",
      "epoch 7 | batch 7 loss: 0.0998735353351\n",
      "epoch 7 | batch 8 loss: 0.0979582890868\n",
      "epoch 7 | batch 9 loss: 0.0929959341884\n",
      "epoch 7 | batch 10 loss: 0.0834820047021\n",
      "epoch 7 | batch 11 loss: 0.093934841454\n",
      "epoch 7 | batch 12 loss: 0.0923690870404\n",
      "epoch 7 | batch 13 loss: 0.0790335610509\n",
      "epoch 7 | batch 14 loss: 0.07982275635\n",
      "epoch 7 | batch 15 loss: 0.0877487361431\n",
      "epoch 7 | batch 16 loss: 0.0831046774983\n",
      "epoch 7 | batch 17 loss: 0.0892027318478\n",
      "epoch 7 | batch 18 loss: 0.0776472762227\n",
      "epoch 7 | batch 19 loss: 0.0859907194972\n",
      "epoch 7 | batch 20 loss: 0.0883834660053\n",
      "epoch 8 | batch 1 loss: 0.0724195539951\n",
      "epoch 8 | batch 2 loss: 0.0885150879622\n",
      "epoch 8 | batch 3 loss: 0.0787020921707\n",
      "epoch 8 | batch 4 loss: 0.0801557600498\n",
      "epoch 8 | batch 5 loss: 0.0961516499519\n",
      "epoch 8 | batch 6 loss: 0.0631021782756\n",
      "epoch 8 | batch 7 loss: 0.0827960520983\n",
      "epoch 8 | batch 8 loss: 0.0688724368811\n",
      "epoch 8 | batch 9 loss: 0.0747528299689\n",
      "epoch 8 | batch 10 loss: 0.0795112028718\n",
      "epoch 8 | batch 11 loss: 0.0854650661349\n",
      "epoch 8 | batch 12 loss: 0.0888159051538\n",
      "epoch 8 | batch 13 loss: 0.078236438334\n",
      "epoch 8 | batch 14 loss: 0.0938884243369\n",
      "epoch 8 | batch 15 loss: 0.0802769064903\n",
      "epoch 8 | batch 16 loss: 0.0731164589524\n",
      "epoch 8 | batch 17 loss: 0.0821812301874\n",
      "epoch 8 | batch 18 loss: 0.0721011012793\n",
      "epoch 8 | batch 19 loss: 0.0714080110192\n",
      "epoch 8 | batch 20 loss: 0.0805274099112\n",
      "epoch 9 | batch 1 loss: 0.059711035341\n",
      "epoch 9 | batch 2 loss: 0.0649119094014\n",
      "epoch 9 | batch 3 loss: 0.0706981644034\n",
      "epoch 9 | batch 4 loss: 0.0670238658786\n",
      "epoch 9 | batch 5 loss: 0.0650237053633\n",
      "epoch 9 | batch 6 loss: 0.066665738821\n",
      "epoch 9 | batch 7 loss: 0.0663920864463\n",
      "epoch 9 | batch 8 loss: 0.0758382901549\n",
      "epoch 9 | batch 9 loss: 0.073289513588\n",
      "epoch 9 | batch 10 loss: 0.071326635778\n",
      "epoch 9 | batch 11 loss: 0.083473674953\n",
      "epoch 9 | batch 12 loss: 0.0668196380138\n",
      "epoch 9 | batch 13 loss: 0.0753244534135\n",
      "epoch 9 | batch 14 loss: 0.069726549089\n",
      "epoch 9 | batch 15 loss: 0.0688155964017\n",
      "epoch 9 | batch 16 loss: 0.0768082439899\n",
      "epoch 9 | batch 17 loss: 0.0592744611204\n",
      "epoch 9 | batch 18 loss: 0.0579874590039\n",
      "epoch 9 | batch 19 loss: 0.0731175094843\n",
      "epoch 9 | batch 20 loss: 0.0897609069943\n",
      "epoch 10 | batch 1 loss: 0.055805336684\n",
      "epoch 10 | batch 2 loss: 0.0677858963609\n",
      "epoch 10 | batch 3 loss: 0.0676390901208\n",
      "epoch 10 | batch 4 loss: 0.0538212284446\n",
      "epoch 10 | batch 5 loss: 0.0604384467006\n",
      "epoch 10 | batch 6 loss: 0.0695964843035\n",
      "epoch 10 | batch 7 loss: 0.0620166361332\n",
      "epoch 10 | batch 8 loss: 0.0539558678865\n",
      "epoch 10 | batch 9 loss: 0.0732351616025\n",
      "epoch 10 | batch 10 loss: 0.0627498626709\n",
      "epoch 10 | batch 11 loss: 0.0693706870079\n",
      "epoch 10 | batch 12 loss: 0.0604336969554\n",
      "epoch 10 | batch 13 loss: 0.0619756430387\n",
      "epoch 10 | batch 14 loss: 0.0707900002599\n",
      "epoch 10 | batch 15 loss: 0.0496479086578\n",
      "epoch 10 | batch 16 loss: 0.0816152989864\n",
      "epoch 10 | batch 17 loss: 0.0611147172749\n",
      "epoch 10 | batch 18 loss: 0.052722401917\n",
      "epoch 10 | batch 19 loss: 0.0561685264111\n",
      "epoch 10 | batch 20 loss: 0.0617689676583\n",
      "epoch 11 | batch 1 loss: 0.0626625269651\n",
      "epoch 11 | batch 2 loss: 0.0544053278863\n",
      "epoch 11 | batch 3 loss: 0.054613571614\n",
      "epoch 11 | batch 4 loss: 0.0558178387582\n",
      "epoch 11 | batch 5 loss: 0.0619389079511\n",
      "epoch 11 | batch 6 loss: 0.0552791915834\n",
      "epoch 11 | batch 7 loss: 0.0502528436482\n",
      "epoch 11 | batch 8 loss: 0.0472663268447\n",
      "epoch 11 | batch 9 loss: 0.0581938065588\n",
      "epoch 11 | batch 10 loss: 0.049689553678\n",
      "epoch 11 | batch 11 loss: 0.0565202720463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 | batch 12 loss: 0.0492650717497\n",
      "epoch 11 | batch 13 loss: 0.0491354167461\n",
      "epoch 11 | batch 14 loss: 0.0548430643976\n",
      "epoch 11 | batch 15 loss: 0.0615501664579\n",
      "epoch 11 | batch 16 loss: 0.0590940192342\n",
      "epoch 11 | batch 17 loss: 0.0568147413433\n",
      "epoch 11 | batch 18 loss: 0.058586679399\n",
      "epoch 11 | batch 19 loss: 0.0589291527867\n",
      "epoch 11 | batch 20 loss: 0.0629076585174\n",
      "epoch 12 | batch 1 loss: 0.0582566410303\n",
      "epoch 12 | batch 2 loss: 0.0465785861015\n",
      "epoch 12 | batch 3 loss: 0.0465272478759\n",
      "epoch 12 | batch 4 loss: 0.0503288693726\n",
      "epoch 12 | batch 5 loss: 0.0483330674469\n",
      "epoch 12 | batch 6 loss: 0.0372797101736\n",
      "epoch 12 | batch 7 loss: 0.0537297055125\n",
      "epoch 12 | batch 8 loss: 0.0420431680977\n",
      "epoch 12 | batch 9 loss: 0.0550136119127\n",
      "epoch 12 | batch 10 loss: 0.052721478045\n",
      "epoch 12 | batch 11 loss: 0.0450317822397\n",
      "epoch 12 | batch 12 loss: 0.0563045367599\n",
      "epoch 12 | batch 13 loss: 0.0575491636992\n",
      "epoch 12 | batch 14 loss: 0.0465667098761\n",
      "epoch 12 | batch 15 loss: 0.0498315617442\n",
      "epoch 12 | batch 16 loss: 0.0518069118261\n",
      "epoch 12 | batch 17 loss: 0.0538460016251\n",
      "epoch 12 | batch 18 loss: 0.0440944433212\n",
      "epoch 12 | batch 19 loss: 0.0466799028218\n",
      "epoch 12 | batch 20 loss: 0.0554656684399\n",
      "epoch 13 | batch 1 loss: 0.0500150769949\n",
      "epoch 13 | batch 2 loss: 0.046426448971\n",
      "epoch 13 | batch 3 loss: 0.0593146122992\n",
      "epoch 13 | batch 4 loss: 0.0509316250682\n",
      "epoch 13 | batch 5 loss: 0.0380700603127\n",
      "epoch 13 | batch 6 loss: 0.0446387827396\n",
      "epoch 13 | batch 7 loss: 0.0348949842155\n",
      "epoch 13 | batch 8 loss: 0.0419693440199\n",
      "epoch 13 | batch 9 loss: 0.0413495339453\n",
      "epoch 13 | batch 10 loss: 0.0461158044636\n",
      "epoch 13 | batch 11 loss: 0.0446909293532\n",
      "epoch 13 | batch 12 loss: 0.045905649662\n",
      "epoch 13 | batch 13 loss: 0.0417226627469\n",
      "epoch 13 | batch 14 loss: 0.0387661606073\n",
      "epoch 13 | batch 15 loss: 0.0368031412363\n",
      "epoch 13 | batch 16 loss: 0.0461992248893\n",
      "epoch 13 | batch 17 loss: 0.0563166961074\n",
      "epoch 13 | batch 18 loss: 0.0452156886458\n",
      "epoch 13 | batch 19 loss: 0.0479842312634\n",
      "epoch 13 | batch 20 loss: 0.0430941730738\n",
      "epoch 14 | batch 1 loss: 0.0327684022486\n",
      "epoch 14 | batch 2 loss: 0.0399384908378\n",
      "epoch 14 | batch 3 loss: 0.039631139487\n",
      "epoch 14 | batch 4 loss: 0.0341056697071\n",
      "epoch 14 | batch 5 loss: 0.0380350537598\n",
      "epoch 14 | batch 6 loss: 0.032973870635\n",
      "epoch 14 | batch 7 loss: 0.0459173694253\n",
      "epoch 14 | batch 8 loss: 0.0375428684056\n",
      "epoch 14 | batch 9 loss: 0.0352647528052\n",
      "epoch 14 | batch 10 loss: 0.0353873632848\n",
      "epoch 14 | batch 11 loss: 0.0371127054095\n",
      "epoch 14 | batch 12 loss: 0.0380260683596\n",
      "epoch 14 | batch 13 loss: 0.0425299182534\n",
      "epoch 14 | batch 14 loss: 0.0531151108444\n",
      "epoch 14 | batch 15 loss: 0.0501941740513\n",
      "epoch 14 | batch 16 loss: 0.0461129844189\n",
      "epoch 14 | batch 17 loss: 0.0350418537855\n",
      "epoch 14 | batch 18 loss: 0.0482137314975\n",
      "epoch 14 | batch 19 loss: 0.0399108417332\n",
      "epoch 14 | batch 20 loss: 0.047045301646\n",
      "epoch 15 | batch 1 loss: 0.0349068008363\n",
      "epoch 15 | batch 2 loss: 0.0414383374155\n",
      "epoch 15 | batch 3 loss: 0.0413655079901\n",
      "epoch 15 | batch 4 loss: 0.0330373421311\n",
      "epoch 15 | batch 5 loss: 0.0389139167964\n",
      "epoch 15 | batch 6 loss: 0.0351767279208\n",
      "epoch 15 | batch 7 loss: 0.0395095199347\n",
      "epoch 15 | batch 8 loss: 0.0303328912705\n",
      "epoch 15 | batch 9 loss: 0.0329181142151\n",
      "epoch 15 | batch 10 loss: 0.0352052822709\n",
      "epoch 15 | batch 11 loss: 0.0343677923083\n",
      "epoch 15 | batch 12 loss: 0.0301261935383\n",
      "epoch 15 | batch 13 loss: 0.0278466716409\n",
      "epoch 15 | batch 14 loss: 0.0475176759064\n",
      "epoch 15 | batch 15 loss: 0.0375919081271\n",
      "epoch 15 | batch 16 loss: 0.0366576574743\n",
      "epoch 15 | batch 17 loss: 0.0391658060253\n",
      "epoch 15 | batch 18 loss: 0.0444782264531\n",
      "epoch 15 | batch 19 loss: 0.0352971106768\n",
      "epoch 15 | batch 20 loss: 0.0313054248691\n",
      "epoch 16 | batch 1 loss: 0.0317333489656\n",
      "epoch 16 | batch 2 loss: 0.0330995693803\n",
      "epoch 16 | batch 3 loss: 0.0327699072659\n",
      "epoch 16 | batch 4 loss: 0.0278694741428\n",
      "epoch 16 | batch 5 loss: 0.0351563356817\n",
      "epoch 16 | batch 6 loss: 0.0334657393396\n",
      "epoch 16 | batch 7 loss: 0.0326501131058\n",
      "epoch 16 | batch 8 loss: 0.0315600819886\n",
      "epoch 16 | batch 9 loss: 0.0383621118963\n",
      "epoch 16 | batch 10 loss: 0.0274859666824\n",
      "epoch 16 | batch 11 loss: 0.0335366055369\n",
      "epoch 16 | batch 12 loss: 0.0299062877893\n",
      "epoch 16 | batch 13 loss: 0.0300926361233\n",
      "epoch 16 | batch 14 loss: 0.036878965795\n",
      "epoch 16 | batch 15 loss: 0.0318185389042\n",
      "epoch 16 | batch 16 loss: 0.0368051566184\n",
      "epoch 16 | batch 17 loss: 0.0376739799976\n",
      "epoch 16 | batch 18 loss: 0.0368248932064\n",
      "epoch 16 | batch 19 loss: 0.0339844785631\n",
      "epoch 16 | batch 20 loss: 0.0279006138444\n",
      "epoch 17 | batch 1 loss: 0.0264074914157\n",
      "epoch 17 | batch 2 loss: 0.0250029657036\n",
      "epoch 17 | batch 3 loss: 0.0323594659567\n",
      "epoch 17 | batch 4 loss: 0.0362682528794\n",
      "epoch 17 | batch 5 loss: 0.0324354954064\n",
      "epoch 17 | batch 6 loss: 0.0312647670507\n",
      "epoch 17 | batch 7 loss: 0.0297479256988\n",
      "epoch 17 | batch 8 loss: 0.0294703040272\n",
      "epoch 17 | batch 9 loss: 0.0260169543326\n",
      "epoch 17 | batch 10 loss: 0.0321488045156\n",
      "epoch 17 | batch 11 loss: 0.0256742835045\n",
      "epoch 17 | batch 12 loss: 0.0336978211999\n",
      "epoch 17 | batch 13 loss: 0.0328608714044\n",
      "epoch 17 | batch 14 loss: 0.0233886353672\n",
      "epoch 17 | batch 15 loss: 0.0415709801018\n",
      "epoch 17 | batch 16 loss: 0.0275205094367\n",
      "epoch 17 | batch 17 loss: 0.0253020189703\n",
      "epoch 17 | batch 18 loss: 0.0240004621446\n",
      "epoch 17 | batch 19 loss: 0.0287832077593\n",
      "epoch 17 | batch 20 loss: 0.032673433423\n",
      "epoch 18 | batch 1 loss: 0.0337001122534\n",
      "epoch 18 | batch 2 loss: 0.0258833058178\n",
      "epoch 18 | batch 3 loss: 0.0265343226492\n",
      "epoch 18 | batch 4 loss: 0.0269827581942\n",
      "epoch 18 | batch 5 loss: 0.0221859812737\n",
      "epoch 18 | batch 6 loss: 0.028006227687\n",
      "epoch 18 | batch 7 loss: 0.0219980832189\n",
      "epoch 18 | batch 8 loss: 0.0212169867009\n",
      "epoch 18 | batch 9 loss: 0.0257613826543\n",
      "epoch 18 | batch 10 loss: 0.0233960878104\n",
      "epoch 18 | batch 11 loss: 0.0267106704414\n",
      "epoch 18 | batch 12 loss: 0.0312900841236\n",
      "epoch 18 | batch 13 loss: 0.0308811701834\n",
      "epoch 18 | batch 14 loss: 0.0247664544731\n",
      "epoch 18 | batch 15 loss: 0.0294493380934\n",
      "epoch 18 | batch 16 loss: 0.0211221240461\n",
      "epoch 18 | batch 17 loss: 0.0276773497462\n",
      "epoch 18 | batch 18 loss: 0.0237003937364\n",
      "epoch 18 | batch 19 loss: 0.0324335284531\n",
      "epoch 18 | batch 20 loss: 0.0357800684869\n",
      "epoch 19 | batch 1 loss: 0.0252998452634\n",
      "epoch 19 | batch 2 loss: 0.0211375560611\n",
      "epoch 19 | batch 3 loss: 0.021769348532\n",
      "epoch 19 | batch 4 loss: 0.0226650293916\n",
      "epoch 19 | batch 5 loss: 0.019649175927\n",
      "epoch 19 | batch 6 loss: 0.0278041921556\n",
      "epoch 19 | batch 7 loss: 0.0246803872287\n",
      "epoch 19 | batch 8 loss: 0.0191203318536\n",
      "epoch 19 | batch 9 loss: 0.0235578529537\n",
      "epoch 19 | batch 10 loss: 0.0249366611242\n",
      "epoch 19 | batch 11 loss: 0.0248233024031\n",
      "epoch 19 | batch 12 loss: 0.0266052726656\n",
      "epoch 19 | batch 13 loss: 0.0224624685943\n",
      "epoch 19 | batch 14 loss: 0.0241556502879\n",
      "epoch 19 | batch 15 loss: 0.0306196827441\n",
      "epoch 19 | batch 16 loss: 0.0208989586681\n",
      "epoch 19 | batch 17 loss: 0.0262669175863\n",
      "epoch 19 | batch 18 loss: 0.0232626758516\n",
      "epoch 19 | batch 19 loss: 0.0280104670674\n",
      "epoch 19 | batch 20 loss: 0.0278451945633\n",
      "epoch 20 | batch 1 loss: 0.01904643327\n",
      "epoch 20 | batch 2 loss: 0.0230378843844\n",
      "epoch 20 | batch 3 loss: 0.0227152630687\n",
      "epoch 20 | batch 4 loss: 0.0177835933864\n",
      "epoch 20 | batch 5 loss: 0.0227648597211\n",
      "epoch 20 | batch 6 loss: 0.0222435984761\n",
      "epoch 20 | batch 7 loss: 0.0198875777423\n",
      "epoch 20 | batch 8 loss: 0.0184032358229\n",
      "epoch 20 | batch 9 loss: 0.0263156332076\n",
      "epoch 20 | batch 10 loss: 0.0235517509282\n",
      "epoch 20 | batch 11 loss: 0.0208649095148\n",
      "epoch 20 | batch 12 loss: 0.019935362041\n",
      "epoch 20 | batch 13 loss: 0.0265541505069\n",
      "epoch 20 | batch 14 loss: 0.0217875614762\n",
      "epoch 20 | batch 15 loss: 0.0191364064813\n",
      "epoch 20 | batch 16 loss: 0.0228472799063\n",
      "epoch 20 | batch 17 loss: 0.0285197906196\n",
      "epoch 20 | batch 18 loss: 0.0175009015948\n",
      "epoch 20 | batch 19 loss: 0.0242442470044\n",
      "epoch 20 | batch 20 loss: 0.023543573916\n",
      "epoch 21 | batch 1 loss: 0.0211658719927\n",
      "epoch 21 | batch 2 loss: 0.0183232314885\n",
      "epoch 21 | batch 3 loss: 0.0178189519793\n",
      "epoch 21 | batch 4 loss: 0.0220973491669\n",
      "epoch 21 | batch 5 loss: 0.025045145303\n",
      "epoch 21 | batch 6 loss: 0.0196356400847\n",
      "epoch 21 | batch 7 loss: 0.021171014756\n",
      "epoch 21 | batch 8 loss: 0.0230157524347\n",
      "epoch 21 | batch 9 loss: 0.0190254673362\n",
      "epoch 21 | batch 10 loss: 0.0231139305979\n",
      "epoch 21 | batch 11 loss: 0.0169591493905\n",
      "epoch 21 | batch 12 loss: 0.0239309482276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 | batch 13 loss: 0.0165460724384\n",
      "epoch 21 | batch 14 loss: 0.0186941102147\n",
      "epoch 21 | batch 15 loss: 0.0166941490024\n",
      "epoch 21 | batch 16 loss: 0.0200935825706\n",
      "epoch 21 | batch 17 loss: 0.0181957092136\n",
      "epoch 21 | batch 18 loss: 0.0199995785952\n",
      "epoch 21 | batch 19 loss: 0.022914448753\n",
      "epoch 21 | batch 20 loss: 0.018631035462\n",
      "epoch 22 | batch 1 loss: 0.0182910691947\n",
      "epoch 22 | batch 2 loss: 0.0171170514077\n",
      "epoch 22 | batch 3 loss: 0.0147491274402\n",
      "epoch 22 | batch 4 loss: 0.0186500009149\n",
      "epoch 22 | batch 5 loss: 0.01369744353\n",
      "epoch 22 | batch 6 loss: 0.0169586855918\n",
      "epoch 22 | batch 7 loss: 0.0187426321208\n",
      "epoch 22 | batch 8 loss: 0.0191771667451\n",
      "epoch 22 | batch 9 loss: 0.024947674945\n",
      "epoch 22 | batch 10 loss: 0.0139393154532\n",
      "epoch 22 | batch 11 loss: 0.020777579397\n",
      "epoch 22 | batch 12 loss: 0.0171928983182\n",
      "epoch 22 | batch 13 loss: 0.0153585327789\n",
      "epoch 22 | batch 14 loss: 0.0208848807961\n",
      "epoch 22 | batch 15 loss: 0.0129057364538\n",
      "epoch 22 | batch 16 loss: 0.0240434166044\n",
      "epoch 22 | batch 17 loss: 0.0185721926391\n",
      "epoch 22 | batch 18 loss: 0.0195436179638\n",
      "epoch 22 | batch 19 loss: 0.0177564080805\n",
      "epoch 22 | batch 20 loss: 0.0197319872677\n",
      "epoch 23 | batch 1 loss: 0.0164466481656\n",
      "epoch 23 | batch 2 loss: 0.0151655273512\n",
      "epoch 23 | batch 3 loss: 0.0183435715735\n",
      "epoch 23 | batch 4 loss: 0.0145475082099\n",
      "epoch 23 | batch 5 loss: 0.0216644182801\n",
      "epoch 23 | batch 6 loss: 0.0176200922579\n",
      "epoch 23 | batch 7 loss: 0.0157789327204\n",
      "epoch 23 | batch 8 loss: 0.0171662755311\n",
      "epoch 23 | batch 9 loss: 0.0162828844041\n",
      "epoch 23 | batch 10 loss: 0.0194047242403\n",
      "epoch 23 | batch 11 loss: 0.0165079496801\n",
      "epoch 23 | batch 12 loss: 0.0224975999445\n",
      "epoch 23 | batch 13 loss: 0.0129707083106\n",
      "epoch 23 | batch 14 loss: 0.0142246624455\n",
      "epoch 23 | batch 15 loss: 0.0155239515007\n",
      "epoch 23 | batch 16 loss: 0.0201560948044\n",
      "epoch 23 | batch 17 loss: 0.0134725524113\n",
      "epoch 23 | batch 18 loss: 0.0135563584045\n",
      "epoch 23 | batch 19 loss: 0.0177433267236\n",
      "epoch 23 | batch 20 loss: 0.0153895951807\n",
      "epoch 24 | batch 1 loss: 0.0120357600972\n",
      "epoch 24 | batch 2 loss: 0.0143835628405\n",
      "epoch 24 | batch 3 loss: 0.0129625955597\n",
      "epoch 24 | batch 4 loss: 0.0166471153498\n",
      "epoch 24 | batch 5 loss: 0.0168658830225\n",
      "epoch 24 | batch 6 loss: 0.0148177621886\n",
      "epoch 24 | batch 7 loss: 0.0150434998795\n",
      "epoch 24 | batch 8 loss: 0.0205758381635\n",
      "epoch 24 | batch 9 loss: 0.0139319738373\n",
      "epoch 24 | batch 10 loss: 0.0160828195512\n",
      "epoch 24 | batch 11 loss: 0.0131292520091\n",
      "epoch 24 | batch 12 loss: 0.0134937744588\n",
      "epoch 24 | batch 13 loss: 0.0209816861898\n",
      "epoch 24 | batch 14 loss: 0.0139246517792\n",
      "epoch 24 | batch 15 loss: 0.014419388026\n",
      "epoch 24 | batch 16 loss: 0.0181722268462\n",
      "epoch 24 | batch 17 loss: 0.0181451737881\n",
      "epoch 24 | batch 18 loss: 0.0145499976352\n",
      "epoch 24 | batch 19 loss: 0.0126945609227\n",
      "epoch 24 | batch 20 loss: 0.0129073765129\n",
      "epoch 25 | batch 1 loss: 0.0151434559375\n",
      "epoch 25 | batch 2 loss: 0.022484075278\n",
      "epoch 25 | batch 3 loss: 0.0141220306978\n",
      "epoch 25 | batch 4 loss: 0.0140589168295\n",
      "epoch 25 | batch 5 loss: 0.013693606481\n",
      "epoch 25 | batch 6 loss: 0.0167028214782\n",
      "epoch 25 | batch 7 loss: 0.0103751448914\n",
      "epoch 25 | batch 8 loss: 0.0129080144688\n",
      "epoch 25 | batch 9 loss: 0.0145688150078\n",
      "epoch 25 | batch 10 loss: 0.0119959339499\n",
      "epoch 25 | batch 11 loss: 0.0149855166674\n",
      "epoch 25 | batch 12 loss: 0.0125247100368\n",
      "epoch 25 | batch 13 loss: 0.0114531628788\n",
      "epoch 25 | batch 14 loss: 0.0125365750864\n",
      "epoch 25 | batch 15 loss: 0.0131391249597\n",
      "epoch 25 | batch 16 loss: 0.0162929780781\n",
      "epoch 25 | batch 17 loss: 0.0137252015993\n",
      "epoch 25 | batch 18 loss: 0.0134465284646\n",
      "epoch 25 | batch 19 loss: 0.0133097982034\n",
      "epoch 25 | batch 20 loss: 0.0113226678222\n",
      "epoch 26 | batch 1 loss: 0.0108702192083\n",
      "epoch 26 | batch 2 loss: 0.0136257633567\n",
      "epoch 26 | batch 3 loss: 0.0145790986717\n",
      "epoch 26 | batch 4 loss: 0.0115333339199\n",
      "epoch 26 | batch 5 loss: 0.00814463105053\n",
      "epoch 26 | batch 6 loss: 0.0107627604157\n",
      "epoch 26 | batch 7 loss: 0.00901467166841\n",
      "epoch 26 | batch 8 loss: 0.0145053537562\n",
      "epoch 26 | batch 9 loss: 0.0146516542882\n",
      "epoch 26 | batch 10 loss: 0.0131989950314\n",
      "epoch 26 | batch 11 loss: 0.0123572824523\n",
      "epoch 26 | batch 12 loss: 0.0182888060808\n",
      "epoch 26 | batch 13 loss: 0.0132470550016\n",
      "epoch 26 | batch 14 loss: 0.0136792408302\n",
      "epoch 26 | batch 15 loss: 0.0138426134363\n",
      "epoch 26 | batch 16 loss: 0.0131499515846\n",
      "epoch 26 | batch 17 loss: 0.0125843584538\n",
      "epoch 26 | batch 18 loss: 0.0101435510442\n",
      "epoch 26 | batch 19 loss: 0.0129551645368\n",
      "epoch 26 | batch 20 loss: 0.0119335763156\n",
      "epoch 27 | batch 1 loss: 0.00993399787694\n",
      "epoch 27 | batch 2 loss: 0.0124715603888\n",
      "epoch 27 | batch 3 loss: 0.0156521685421\n",
      "epoch 27 | batch 4 loss: 0.00798417720944\n",
      "epoch 27 | batch 5 loss: 0.0101843746379\n",
      "epoch 27 | batch 6 loss: 0.0100350128487\n",
      "epoch 27 | batch 7 loss: 0.0118232723325\n",
      "epoch 27 | batch 8 loss: 0.0120342569426\n",
      "epoch 27 | batch 9 loss: 0.0110407574102\n",
      "epoch 27 | batch 10 loss: 0.0111159607768\n",
      "epoch 27 | batch 11 loss: 0.0100536188111\n",
      "epoch 27 | batch 12 loss: 0.0131998481229\n",
      "epoch 27 | batch 13 loss: 0.0135023323819\n",
      "epoch 27 | batch 14 loss: 0.00987326540053\n",
      "epoch 27 | batch 15 loss: 0.00933432858437\n",
      "epoch 27 | batch 16 loss: 0.013447612524\n",
      "epoch 27 | batch 17 loss: 0.0119763286784\n",
      "epoch 27 | batch 18 loss: 0.0132768023759\n",
      "epoch 27 | batch 19 loss: 0.0114003792405\n",
      "epoch 27 | batch 20 loss: 0.0136309564114\n",
      "epoch 28 | batch 1 loss: 0.00816148426384\n",
      "epoch 28 | batch 2 loss: 0.0101851578802\n",
      "epoch 28 | batch 3 loss: 0.0111100869253\n",
      "epoch 28 | batch 4 loss: 0.0113944169134\n",
      "epoch 28 | batch 5 loss: 0.0130860134959\n",
      "epoch 28 | batch 6 loss: 0.0103930654004\n",
      "epoch 28 | batch 7 loss: 0.0107094952837\n",
      "epoch 28 | batch 8 loss: 0.0113069852814\n",
      "epoch 28 | batch 9 loss: 0.00913625862449\n",
      "epoch 28 | batch 10 loss: 0.0105180684477\n",
      "epoch 28 | batch 11 loss: 0.0121165085584\n",
      "epoch 28 | batch 12 loss: 0.0125232432038\n",
      "epoch 28 | batch 13 loss: 0.00959596876055\n",
      "epoch 28 | batch 14 loss: 0.0142077207565\n",
      "epoch 28 | batch 15 loss: 0.00848720595241\n",
      "epoch 28 | batch 16 loss: 0.0103456126526\n",
      "epoch 28 | batch 17 loss: 0.00878954585642\n",
      "epoch 28 | batch 18 loss: 0.0082140462473\n",
      "epoch 28 | batch 19 loss: 0.010633636266\n",
      "epoch 28 | batch 20 loss: 0.0122095188126\n",
      "epoch 29 | batch 1 loss: 0.00816258974373\n",
      "epoch 29 | batch 2 loss: 0.0105100898072\n",
      "epoch 29 | batch 3 loss: 0.00663091382012\n",
      "epoch 29 | batch 4 loss: 0.00996981654316\n",
      "epoch 29 | batch 5 loss: 0.00777161261067\n",
      "epoch 29 | batch 6 loss: 0.00868083722889\n",
      "epoch 29 | batch 7 loss: 0.0112884538248\n",
      "epoch 29 | batch 8 loss: 0.00952632259578\n",
      "epoch 29 | batch 9 loss: 0.0133464979008\n",
      "epoch 29 | batch 10 loss: 0.00826253090054\n",
      "epoch 29 | batch 11 loss: 0.0100497631356\n",
      "epoch 29 | batch 12 loss: 0.0105753559619\n",
      "epoch 29 | batch 13 loss: 0.010822866112\n",
      "epoch 29 | batch 14 loss: 0.0100154466927\n",
      "epoch 29 | batch 15 loss: 0.00883129797876\n",
      "epoch 29 | batch 16 loss: 0.0105009004474\n",
      "epoch 29 | batch 17 loss: 0.00792314112186\n",
      "epoch 29 | batch 18 loss: 0.0117922415957\n",
      "epoch 29 | batch 19 loss: 0.00887603126466\n",
      "epoch 29 | batch 20 loss: 0.0113310525194\n",
      "epoch 30 | batch 1 loss: 0.00894436892122\n",
      "epoch 30 | batch 2 loss: 0.00751770287752\n",
      "epoch 30 | batch 3 loss: 0.00652664992958\n",
      "epoch 30 | batch 4 loss: 0.00923814531416\n",
      "epoch 30 | batch 5 loss: 0.00870942976326\n",
      "epoch 30 | batch 6 loss: 0.00775379640982\n",
      "epoch 30 | batch 7 loss: 0.0067450478673\n",
      "epoch 30 | batch 8 loss: 0.00682881940156\n",
      "epoch 30 | batch 9 loss: 0.00813231244683\n",
      "epoch 30 | batch 10 loss: 0.00939633790404\n",
      "epoch 30 | batch 11 loss: 0.00787595193833\n",
      "epoch 30 | batch 12 loss: 0.00903795938939\n",
      "epoch 30 | batch 13 loss: 0.00942494068295\n",
      "epoch 30 | batch 14 loss: 0.0113641303033\n",
      "epoch 30 | batch 15 loss: 0.0165028721094\n",
      "epoch 30 | batch 16 loss: 0.0100465193391\n",
      "epoch 30 | batch 17 loss: 0.00941162277013\n",
      "epoch 30 | batch 18 loss: 0.0113416695967\n",
      "epoch 30 | batch 19 loss: 0.00936524663121\n",
      "epoch 30 | batch 20 loss: 0.00795839074999\n",
      "epoch 31 | batch 1 loss: 0.00759722851217\n",
      "epoch 31 | batch 2 loss: 0.00778490118682\n",
      "epoch 31 | batch 3 loss: 0.00778656126931\n",
      "epoch 31 | batch 4 loss: 0.0103578763083\n",
      "epoch 31 | batch 5 loss: 0.00800976064056\n",
      "epoch 31 | batch 6 loss: 0.00824847910553\n",
      "epoch 31 | batch 7 loss: 0.00777667760849\n",
      "epoch 31 | batch 8 loss: 0.00716964574531\n",
      "epoch 31 | batch 9 loss: 0.00813485309482\n",
      "epoch 31 | batch 10 loss: 0.00848625134677\n",
      "epoch 31 | batch 11 loss: 0.0105784153566\n",
      "epoch 31 | batch 12 loss: 0.00705981208012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 | batch 13 loss: 0.00913082342595\n",
      "epoch 31 | batch 14 loss: 0.00903428439051\n",
      "epoch 31 | batch 15 loss: 0.00723793776706\n",
      "epoch 31 | batch 16 loss: 0.0141198728234\n",
      "epoch 31 | batch 17 loss: 0.00625444529578\n",
      "epoch 31 | batch 18 loss: 0.00760471588001\n",
      "epoch 31 | batch 19 loss: 0.00696515012532\n",
      "epoch 31 | batch 20 loss: 0.008530725725\n",
      "epoch 32 | batch 1 loss: 0.00762152438983\n",
      "epoch 32 | batch 2 loss: 0.00703844381496\n",
      "epoch 32 | batch 3 loss: 0.00926111824811\n",
      "epoch 32 | batch 4 loss: 0.00933346617967\n",
      "epoch 32 | batch 5 loss: 0.0083819963038\n",
      "epoch 32 | batch 6 loss: 0.00648722983897\n",
      "epoch 32 | batch 7 loss: 0.00918870512396\n",
      "epoch 32 | batch 8 loss: 0.00685628177598\n",
      "epoch 32 | batch 9 loss: 0.00764460628852\n",
      "epoch 32 | batch 10 loss: 0.00599967455491\n",
      "epoch 32 | batch 11 loss: 0.00771780405194\n",
      "epoch 32 | batch 12 loss: 0.00633315229788\n",
      "epoch 32 | batch 13 loss: 0.0064616156742\n",
      "epoch 32 | batch 14 loss: 0.00646134559065\n",
      "epoch 32 | batch 15 loss: 0.00708282040432\n",
      "epoch 32 | batch 16 loss: 0.011485052295\n",
      "epoch 32 | batch 17 loss: 0.00988396815956\n",
      "epoch 32 | batch 18 loss: 0.00847460143268\n",
      "epoch 32 | batch 19 loss: 0.00652952026576\n",
      "epoch 32 | batch 20 loss: 0.00759570673108\n",
      "epoch 33 | batch 1 loss: 0.00624492159113\n",
      "epoch 33 | batch 2 loss: 0.00683950819075\n",
      "epoch 33 | batch 3 loss: 0.00586690381169\n",
      "epoch 33 | batch 4 loss: 0.00848880782723\n",
      "epoch 33 | batch 5 loss: 0.00777413044125\n",
      "epoch 33 | batch 6 loss: 0.00901381019503\n",
      "epoch 33 | batch 7 loss: 0.00638518389314\n",
      "epoch 33 | batch 8 loss: 0.00569602567703\n",
      "epoch 33 | batch 9 loss: 0.00654969550669\n",
      "epoch 33 | batch 10 loss: 0.00834443327039\n",
      "epoch 33 | batch 11 loss: 0.00725202355534\n",
      "epoch 33 | batch 12 loss: 0.00713831186295\n",
      "epoch 33 | batch 13 loss: 0.00851570349187\n",
      "epoch 33 | batch 14 loss: 0.00712006306276\n",
      "epoch 33 | batch 15 loss: 0.00898217596114\n",
      "epoch 33 | batch 16 loss: 0.00694513367489\n",
      "epoch 33 | batch 17 loss: 0.00637050904334\n",
      "epoch 33 | batch 18 loss: 0.00623853923753\n",
      "epoch 33 | batch 19 loss: 0.00568714970723\n",
      "epoch 33 | batch 20 loss: 0.00786574464291\n",
      "epoch 34 | batch 1 loss: 0.00593398604542\n",
      "epoch 34 | batch 2 loss: 0.00931479409337\n",
      "epoch 34 | batch 3 loss: 0.00849606934935\n",
      "epoch 34 | batch 4 loss: 0.00682915793732\n",
      "epoch 34 | batch 5 loss: 0.00667769508436\n",
      "epoch 34 | batch 6 loss: 0.00623195851222\n",
      "epoch 34 | batch 7 loss: 0.00618274556473\n",
      "epoch 34 | batch 8 loss: 0.00624159630388\n",
      "epoch 34 | batch 9 loss: 0.00689152954146\n",
      "epoch 34 | batch 10 loss: 0.00582366902381\n",
      "epoch 34 | batch 11 loss: 0.00619958247989\n",
      "epoch 34 | batch 12 loss: 0.00677181687206\n",
      "epoch 34 | batch 13 loss: 0.00658675143495\n",
      "epoch 34 | batch 14 loss: 0.00776050752029\n",
      "epoch 34 | batch 15 loss: 0.00584374321625\n",
      "epoch 34 | batch 16 loss: 0.00749257905409\n",
      "epoch 34 | batch 17 loss: 0.00679415510967\n",
      "epoch 34 | batch 18 loss: 0.00514299282804\n",
      "epoch 34 | batch 19 loss: 0.00688459118828\n",
      "epoch 34 | batch 20 loss: 0.00619351211935\n",
      "epoch 35 | batch 1 loss: 0.00629716739058\n",
      "epoch 35 | batch 2 loss: 0.0065875952132\n",
      "epoch 35 | batch 3 loss: 0.00615934887901\n",
      "epoch 35 | batch 4 loss: 0.00640036631376\n",
      "epoch 35 | batch 5 loss: 0.00824860483408\n",
      "epoch 35 | batch 6 loss: 0.0055837566033\n",
      "epoch 35 | batch 7 loss: 0.0068939095363\n",
      "epoch 35 | batch 8 loss: 0.00629322836176\n",
      "epoch 35 | batch 9 loss: 0.0056052361615\n",
      "epoch 35 | batch 10 loss: 0.0057488232851\n",
      "epoch 35 | batch 11 loss: 0.00638263951987\n",
      "epoch 35 | batch 12 loss: 0.00545265246183\n",
      "epoch 35 | batch 13 loss: 0.00595592707396\n",
      "epoch 35 | batch 14 loss: 0.00588402384892\n",
      "epoch 35 | batch 15 loss: 0.00706780515611\n",
      "epoch 35 | batch 16 loss: 0.00604342389852\n",
      "epoch 35 | batch 17 loss: 0.00457145925611\n",
      "epoch 35 | batch 18 loss: 0.00844385940582\n",
      "epoch 35 | batch 19 loss: 0.00609304429963\n",
      "epoch 35 | batch 20 loss: 0.00519855692983\n",
      "epoch 36 | batch 1 loss: 0.0062146675773\n",
      "epoch 36 | batch 2 loss: 0.00613147113472\n",
      "epoch 36 | batch 3 loss: 0.00630675489083\n",
      "epoch 36 | batch 4 loss: 0.00458204001188\n",
      "epoch 36 | batch 5 loss: 0.00448696548119\n",
      "epoch 36 | batch 6 loss: 0.00601834617555\n",
      "epoch 36 | batch 7 loss: 0.0064916559495\n",
      "epoch 36 | batch 8 loss: 0.0066792932339\n",
      "epoch 36 | batch 9 loss: 0.0054758223705\n",
      "epoch 36 | batch 10 loss: 0.006229985971\n",
      "epoch 36 | batch 11 loss: 0.00579730374739\n",
      "epoch 36 | batch 12 loss: 0.00573959108442\n",
      "epoch 36 | batch 13 loss: 0.00580740207806\n",
      "epoch 36 | batch 14 loss: 0.0045641460456\n",
      "epoch 36 | batch 15 loss: 0.00621242076159\n",
      "epoch 36 | batch 16 loss: 0.00621324265376\n",
      "epoch 36 | batch 17 loss: 0.00571017153561\n",
      "epoch 36 | batch 18 loss: 0.00541403470561\n",
      "epoch 36 | batch 19 loss: 0.00897746626288\n",
      "epoch 36 | batch 20 loss: 0.00505089433864\n",
      "epoch 37 | batch 1 loss: 0.00451595894992\n",
      "epoch 37 | batch 2 loss: 0.00643007783219\n",
      "epoch 37 | batch 3 loss: 0.00456258794293\n",
      "epoch 37 | batch 4 loss: 0.00500514917076\n",
      "epoch 37 | batch 5 loss: 0.00812799483538\n",
      "epoch 37 | batch 6 loss: 0.00480716722086\n",
      "epoch 37 | batch 7 loss: 0.00450662663206\n",
      "epoch 37 | batch 8 loss: 0.00817211158574\n",
      "epoch 37 | batch 9 loss: 0.0062893810682\n",
      "epoch 37 | batch 10 loss: 0.00546453520656\n",
      "epoch 37 | batch 11 loss: 0.00424794806167\n",
      "epoch 37 | batch 12 loss: 0.00581351667643\n",
      "epoch 37 | batch 13 loss: 0.00473476247862\n",
      "epoch 37 | batch 14 loss: 0.00567829562351\n",
      "epoch 37 | batch 15 loss: 0.00524810049683\n",
      "epoch 37 | batch 16 loss: 0.00716052111238\n",
      "epoch 37 | batch 17 loss: 0.0047544403933\n",
      "epoch 37 | batch 18 loss: 0.0048994962126\n",
      "epoch 37 | batch 19 loss: 0.00446417322382\n",
      "epoch 37 | batch 20 loss: 0.00541322818026\n",
      "epoch 38 | batch 1 loss: 0.00464699789882\n",
      "epoch 38 | batch 2 loss: 0.00714659504592\n",
      "epoch 38 | batch 3 loss: 0.004937376827\n",
      "epoch 38 | batch 4 loss: 0.00433657690883\n",
      "epoch 38 | batch 5 loss: 0.0045686904341\n",
      "epoch 38 | batch 6 loss: 0.00414796220139\n",
      "epoch 38 | batch 7 loss: 0.00442141713575\n",
      "epoch 38 | batch 8 loss: 0.00467823725194\n",
      "epoch 38 | batch 9 loss: 0.00351021694951\n",
      "epoch 38 | batch 10 loss: 0.0051563186571\n",
      "epoch 38 | batch 11 loss: 0.00439873570576\n",
      "epoch 38 | batch 12 loss: 0.00487446365878\n",
      "epoch 38 | batch 13 loss: 0.00427851406857\n",
      "epoch 38 | batch 14 loss: 0.00632510241121\n",
      "epoch 38 | batch 15 loss: 0.00819744728506\n",
      "epoch 38 | batch 16 loss: 0.00542050041258\n",
      "epoch 38 | batch 17 loss: 0.00547490548342\n",
      "epoch 38 | batch 18 loss: 0.00489378161728\n",
      "epoch 38 | batch 19 loss: 0.0048908572644\n",
      "epoch 38 | batch 20 loss: 0.00710729463026\n",
      "epoch 39 | batch 1 loss: 0.00446806102991\n",
      "epoch 39 | batch 2 loss: 0.00710222870111\n",
      "epoch 39 | batch 3 loss: 0.00408528884873\n",
      "epoch 39 | batch 4 loss: 0.00435947999358\n",
      "epoch 39 | batch 5 loss: 0.00434704776853\n",
      "epoch 39 | batch 6 loss: 0.0050207846798\n",
      "epoch 39 | batch 7 loss: 0.00542768463492\n",
      "epoch 39 | batch 8 loss: 0.00395151646808\n",
      "epoch 39 | batch 9 loss: 0.0048265280202\n",
      "epoch 39 | batch 10 loss: 0.00395361753181\n",
      "epoch 39 | batch 11 loss: 0.00495642377064\n",
      "epoch 39 | batch 12 loss: 0.00355011993088\n",
      "epoch 39 | batch 13 loss: 0.00502469297498\n",
      "epoch 39 | batch 14 loss: 0.00393515499309\n",
      "epoch 39 | batch 15 loss: 0.00391382351518\n",
      "epoch 39 | batch 16 loss: 0.00433600693941\n",
      "epoch 39 | batch 17 loss: 0.00441447552294\n",
      "epoch 39 | batch 18 loss: 0.00565653853118\n",
      "epoch 39 | batch 19 loss: 0.00585283804685\n",
      "epoch 39 | batch 20 loss: 0.00839449465275\n",
      "epoch 40 | batch 1 loss: 0.00458839628845\n",
      "epoch 40 | batch 2 loss: 0.00410420401022\n",
      "epoch 40 | batch 3 loss: 0.00710733095184\n",
      "epoch 40 | batch 4 loss: 0.00439603207633\n",
      "epoch 40 | batch 5 loss: 0.00410128477961\n",
      "epoch 40 | batch 6 loss: 0.0056722080335\n",
      "epoch 40 | batch 7 loss: 0.00474940380082\n",
      "epoch 40 | batch 8 loss: 0.00571006117389\n",
      "epoch 40 | batch 9 loss: 0.00383914657868\n",
      "epoch 40 | batch 10 loss: 0.00531504070386\n",
      "epoch 40 | batch 11 loss: 0.0041191726923\n",
      "epoch 40 | batch 12 loss: 0.00440540770069\n",
      "epoch 40 | batch 13 loss: 0.00341165531427\n",
      "epoch 40 | batch 14 loss: 0.00512220012024\n",
      "epoch 40 | batch 15 loss: 0.00364989344962\n",
      "epoch 40 | batch 16 loss: 0.00361882778816\n",
      "epoch 40 | batch 17 loss: 0.00511224381626\n",
      "epoch 40 | batch 18 loss: 0.00419802963734\n",
      "epoch 40 | batch 19 loss: 0.00563514279202\n",
      "epoch 40 | batch 20 loss: 0.00345998699777\n",
      "epoch 41 | batch 1 loss: 0.00444220844656\n",
      "epoch 41 | batch 2 loss: 0.00413366453722\n",
      "epoch 41 | batch 3 loss: 0.00358520657755\n",
      "epoch 41 | batch 4 loss: 0.00413386058062\n",
      "epoch 41 | batch 5 loss: 0.00491519086063\n",
      "epoch 41 | batch 6 loss: 0.00488677015528\n",
      "epoch 41 | batch 7 loss: 0.00381986657158\n",
      "epoch 41 | batch 8 loss: 0.00357978628017\n",
      "epoch 41 | batch 9 loss: 0.00446116551757\n",
      "epoch 41 | batch 10 loss: 0.00343781290576\n",
      "epoch 41 | batch 11 loss: 0.00682950206101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41 | batch 12 loss: 0.00463056610897\n",
      "epoch 41 | batch 13 loss: 0.00423014769331\n",
      "epoch 41 | batch 14 loss: 0.00418936274946\n",
      "epoch 41 | batch 15 loss: 0.00408421177417\n",
      "epoch 41 | batch 16 loss: 0.00477712741122\n",
      "epoch 41 | batch 17 loss: 0.00457600643858\n",
      "epoch 41 | batch 18 loss: 0.00389662967063\n",
      "epoch 41 | batch 19 loss: 0.00482527632266\n",
      "epoch 41 | batch 20 loss: 0.00364958262071\n",
      "epoch 42 | batch 1 loss: 0.00297097628936\n",
      "epoch 42 | batch 2 loss: 0.00358231994323\n",
      "epoch 42 | batch 3 loss: 0.00370639259927\n",
      "epoch 42 | batch 4 loss: 0.00345232826658\n",
      "epoch 42 | batch 5 loss: 0.00416194833815\n",
      "epoch 42 | batch 6 loss: 0.00393915409222\n",
      "epoch 42 | batch 7 loss: 0.00736629823223\n",
      "epoch 42 | batch 8 loss: 0.00407224008814\n",
      "epoch 42 | batch 9 loss: 0.00437977164984\n",
      "epoch 42 | batch 10 loss: 0.00359717430547\n",
      "epoch 42 | batch 11 loss: 0.00356913497671\n",
      "epoch 42 | batch 12 loss: 0.00483965687454\n",
      "epoch 42 | batch 13 loss: 0.00429230742157\n",
      "epoch 42 | batch 14 loss: 0.00459922943264\n",
      "epoch 42 | batch 15 loss: 0.00355709786527\n",
      "epoch 42 | batch 16 loss: 0.00437730038539\n",
      "epoch 42 | batch 17 loss: 0.0036875072401\n",
      "epoch 42 | batch 18 loss: 0.00409754132852\n",
      "epoch 42 | batch 19 loss: 0.00357976555824\n",
      "epoch 42 | batch 20 loss: 0.00458636833355\n",
      "epoch 43 | batch 1 loss: 0.00328369322233\n",
      "epoch 43 | batch 2 loss: 0.00351203675382\n",
      "epoch 43 | batch 3 loss: 0.00386882713065\n",
      "epoch 43 | batch 4 loss: 0.00593587430194\n",
      "epoch 43 | batch 5 loss: 0.00303302658722\n",
      "epoch 43 | batch 6 loss: 0.0029504657723\n",
      "epoch 43 | batch 7 loss: 0.00298069929704\n",
      "epoch 43 | batch 8 loss: 0.0049067880027\n",
      "epoch 43 | batch 9 loss: 0.00483703566715\n",
      "epoch 43 | batch 10 loss: 0.00356306205504\n",
      "epoch 43 | batch 11 loss: 0.00463671796024\n",
      "epoch 43 | batch 12 loss: 0.00359981763177\n",
      "epoch 43 | batch 13 loss: 0.00394841423258\n",
      "epoch 43 | batch 14 loss: 0.00428670085967\n",
      "epoch 43 | batch 15 loss: 0.0042261723429\n",
      "epoch 43 | batch 16 loss: 0.00358003308065\n",
      "epoch 43 | batch 17 loss: 0.00465488387272\n",
      "epoch 43 | batch 18 loss: 0.00344194285572\n",
      "epoch 43 | batch 19 loss: 0.00394343165681\n",
      "epoch 43 | batch 20 loss: 0.00312727713026\n",
      "epoch 44 | batch 1 loss: 0.00339854089543\n",
      "epoch 44 | batch 2 loss: 0.00295187882148\n",
      "epoch 44 | batch 3 loss: 0.00572129804641\n",
      "epoch 44 | batch 4 loss: 0.00391310360283\n",
      "epoch 44 | batch 5 loss: 0.00404683640227\n",
      "epoch 44 | batch 6 loss: 0.00292697362602\n",
      "epoch 44 | batch 7 loss: 0.00317646213807\n",
      "epoch 44 | batch 8 loss: 0.00377339310944\n",
      "epoch 44 | batch 9 loss: 0.00406256783754\n",
      "epoch 44 | batch 10 loss: 0.00384343974292\n",
      "epoch 44 | batch 11 loss: 0.0035848536063\n",
      "epoch 44 | batch 12 loss: 0.0037657013163\n",
      "epoch 44 | batch 13 loss: 0.00393830332905\n",
      "epoch 44 | batch 14 loss: 0.00327370665036\n",
      "epoch 44 | batch 15 loss: 0.00309859309345\n",
      "epoch 44 | batch 16 loss: 0.00378295010887\n",
      "epoch 44 | batch 17 loss: 0.00404370808974\n",
      "epoch 44 | batch 18 loss: 0.00440018298104\n",
      "epoch 44 | batch 19 loss: 0.00301798502915\n",
      "epoch 44 | batch 20 loss: 0.00343140703626\n",
      "epoch 45 | batch 1 loss: 0.00292707351036\n",
      "epoch 45 | batch 2 loss: 0.00362890819088\n",
      "epoch 45 | batch 3 loss: 0.00351704796776\n",
      "epoch 45 | batch 4 loss: 0.00325855403207\n",
      "epoch 45 | batch 5 loss: 0.00724095478654\n",
      "epoch 45 | batch 6 loss: 0.00332414777949\n",
      "epoch 45 | batch 7 loss: 0.00317161274143\n",
      "epoch 45 | batch 8 loss: 0.00326174031943\n",
      "epoch 45 | batch 9 loss: 0.00420950399712\n",
      "epoch 45 | batch 10 loss: 0.0038399763871\n",
      "epoch 45 | batch 11 loss: 0.003081161296\n",
      "epoch 45 | batch 12 loss: 0.00319453212433\n",
      "epoch 45 | batch 13 loss: 0.00340817123652\n",
      "epoch 45 | batch 14 loss: 0.00263311644085\n",
      "epoch 45 | batch 15 loss: 0.00306177511811\n",
      "epoch 45 | batch 16 loss: 0.00390148046426\n",
      "epoch 45 | batch 17 loss: 0.00290912506171\n",
      "epoch 45 | batch 18 loss: 0.00327539280988\n",
      "epoch 45 | batch 19 loss: 0.00357810105197\n",
      "epoch 45 | batch 20 loss: 0.00348222139291\n",
      "epoch 46 | batch 1 loss: 0.00341564137489\n",
      "epoch 46 | batch 2 loss: 0.00354670267552\n",
      "epoch 46 | batch 3 loss: 0.00304250465706\n",
      "epoch 46 | batch 4 loss: 0.00259179109707\n",
      "epoch 46 | batch 5 loss: 0.00298546324484\n",
      "epoch 46 | batch 6 loss: 0.00309549365193\n",
      "epoch 46 | batch 7 loss: 0.00421814480796\n",
      "epoch 46 | batch 8 loss: 0.00426086690277\n",
      "epoch 46 | batch 9 loss: 0.0029953699559\n",
      "epoch 46 | batch 10 loss: 0.00374122266658\n",
      "epoch 46 | batch 11 loss: 0.00373630644754\n",
      "epoch 46 | batch 12 loss: 0.00338077358902\n",
      "epoch 46 | batch 13 loss: 0.00347470049746\n",
      "epoch 46 | batch 14 loss: 0.0031188277062\n",
      "epoch 46 | batch 15 loss: 0.00302847800776\n",
      "epoch 46 | batch 16 loss: 0.00314109586179\n",
      "epoch 46 | batch 17 loss: 0.00353112374432\n",
      "epoch 46 | batch 18 loss: 0.0030089749489\n",
      "epoch 46 | batch 19 loss: 0.00323134521022\n",
      "epoch 46 | batch 20 loss: 0.00369939999655\n",
      "epoch 47 | batch 1 loss: 0.00298087019473\n",
      "epoch 47 | batch 2 loss: 0.00456653302535\n",
      "epoch 47 | batch 3 loss: 0.00223567639478\n",
      "epoch 47 | batch 4 loss: 0.00330432923511\n",
      "epoch 47 | batch 5 loss: 0.00300666433759\n",
      "epoch 47 | batch 6 loss: 0.00451183877885\n",
      "epoch 47 | batch 7 loss: 0.00308295851573\n",
      "epoch 47 | batch 8 loss: 0.00311681116\n",
      "epoch 47 | batch 9 loss: 0.00277705979533\n",
      "epoch 47 | batch 10 loss: 0.00240444019437\n",
      "epoch 47 | batch 11 loss: 0.00277872243896\n",
      "epoch 47 | batch 12 loss: 0.00305394968018\n",
      "epoch 47 | batch 13 loss: 0.00273509253748\n",
      "epoch 47 | batch 14 loss: 0.00398907996714\n",
      "epoch 47 | batch 15 loss: 0.00267636869103\n",
      "epoch 47 | batch 16 loss: 0.00267262686975\n",
      "epoch 47 | batch 17 loss: 0.00286233448423\n",
      "epoch 47 | batch 18 loss: 0.00364773441106\n",
      "epoch 47 | batch 19 loss: 0.00388635857962\n",
      "epoch 47 | batch 20 loss: 0.00372071238235\n",
      "epoch 48 | batch 1 loss: 0.00333478418179\n",
      "epoch 48 | batch 2 loss: 0.00244210613891\n",
      "epoch 48 | batch 3 loss: 0.00254938448779\n",
      "epoch 48 | batch 4 loss: 0.00429154234007\n",
      "epoch 48 | batch 5 loss: 0.0027606303338\n",
      "epoch 48 | batch 6 loss: 0.00268522580154\n",
      "epoch 48 | batch 7 loss: 0.00220361445099\n",
      "epoch 48 | batch 8 loss: 0.00379755115137\n",
      "epoch 48 | batch 9 loss: 0.00418235175312\n",
      "epoch 48 | batch 10 loss: 0.00273274257779\n",
      "epoch 48 | batch 11 loss: 0.00344720459543\n",
      "epoch 48 | batch 12 loss: 0.00293902843259\n",
      "epoch 48 | batch 13 loss: 0.00396235287189\n",
      "epoch 48 | batch 14 loss: 0.00208832556382\n",
      "epoch 48 | batch 15 loss: 0.00274262647144\n",
      "epoch 48 | batch 16 loss: 0.00288264104165\n",
      "epoch 48 | batch 17 loss: 0.00251225731336\n",
      "epoch 48 | batch 18 loss: 0.00441038236022\n",
      "epoch 48 | batch 19 loss: 0.00260582310148\n",
      "epoch 48 | batch 20 loss: 0.00278515461832\n",
      "epoch 49 | batch 1 loss: 0.00314955902286\n",
      "epoch 49 | batch 2 loss: 0.00243628583848\n",
      "epoch 49 | batch 3 loss: 0.00292869703844\n",
      "epoch 49 | batch 4 loss: 0.00284756720066\n",
      "epoch 49 | batch 5 loss: 0.00278919865377\n",
      "epoch 49 | batch 6 loss: 0.00253150938079\n",
      "epoch 49 | batch 7 loss: 0.00220814300701\n",
      "epoch 49 | batch 8 loss: 0.00244524469599\n",
      "epoch 49 | batch 9 loss: 0.00304757570848\n",
      "epoch 49 | batch 10 loss: 0.00245029851794\n",
      "epoch 49 | batch 11 loss: 0.00229191128165\n",
      "epoch 49 | batch 12 loss: 0.00326040899381\n",
      "epoch 49 | batch 13 loss: 0.00286339828745\n",
      "epoch 49 | batch 14 loss: 0.00364662031643\n",
      "epoch 49 | batch 15 loss: 0.0037960796617\n",
      "epoch 49 | batch 16 loss: 0.00287579954602\n",
      "epoch 49 | batch 17 loss: 0.00415313662961\n",
      "epoch 49 | batch 18 loss: 0.00326258945279\n",
      "epoch 49 | batch 19 loss: 0.00289867189713\n",
      "epoch 49 | batch 20 loss: 0.0027302459348\n",
      "epoch 50 | batch 1 loss: 0.00241178064607\n",
      "epoch 50 | batch 2 loss: 0.0028170181904\n",
      "epoch 50 | batch 3 loss: 0.00399152794853\n",
      "epoch 50 | batch 4 loss: 0.00219564908184\n",
      "epoch 50 | batch 5 loss: 0.00289341039024\n",
      "epoch 50 | batch 6 loss: 0.00338619644754\n",
      "epoch 50 | batch 7 loss: 0.00229469919577\n",
      "epoch 50 | batch 8 loss: 0.00275088497438\n",
      "epoch 50 | batch 9 loss: 0.00246321968734\n",
      "epoch 50 | batch 10 loss: 0.0029674784746\n",
      "epoch 50 | batch 11 loss: 0.00364874210209\n",
      "epoch 50 | batch 12 loss: 0.00265827123076\n",
      "epoch 50 | batch 13 loss: 0.00229677162133\n",
      "epoch 50 | batch 14 loss: 0.00285647041164\n",
      "epoch 50 | batch 15 loss: 0.00303729437292\n",
      "epoch 50 | batch 16 loss: 0.00267978548072\n",
      "epoch 50 | batch 17 loss: 0.00296657183208\n",
      "epoch 50 | batch 18 loss: 0.00299395457841\n",
      "epoch 50 | batch 19 loss: 0.00239874026738\n",
      "epoch 50 | batch 20 loss: 0.0029983909335\n",
      "epoch 51 | batch 1 loss: 0.00309525360353\n",
      "epoch 51 | batch 2 loss: 0.00225869123824\n",
      "epoch 51 | batch 3 loss: 0.00259159971029\n",
      "epoch 51 | batch 4 loss: 0.00196751765907\n",
      "epoch 51 | batch 5 loss: 0.00243187975138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51 | batch 6 loss: 0.0026480879169\n",
      "epoch 51 | batch 7 loss: 0.00320797879249\n",
      "epoch 51 | batch 8 loss: 0.00278991786763\n",
      "epoch 51 | batch 9 loss: 0.00254595838487\n",
      "epoch 51 | batch 10 loss: 0.00330721447244\n",
      "epoch 51 | batch 11 loss: 0.00226444331929\n",
      "epoch 51 | batch 12 loss: 0.00233503151685\n",
      "epoch 51 | batch 13 loss: 0.00268502882682\n",
      "epoch 51 | batch 14 loss: 0.00394379161298\n",
      "epoch 51 | batch 15 loss: 0.00257721636444\n",
      "epoch 51 | batch 16 loss: 0.00319420476444\n",
      "epoch 51 | batch 17 loss: 0.00265809590928\n",
      "epoch 51 | batch 18 loss: 0.00289847701788\n",
      "epoch 51 | batch 19 loss: 0.00229653483257\n",
      "epoch 51 | batch 20 loss: 0.00211356836371\n",
      "epoch 52 | batch 1 loss: 0.00323544652201\n",
      "epoch 52 | batch 2 loss: 0.00290271593258\n",
      "epoch 52 | batch 3 loss: 0.00244389404543\n",
      "epoch 52 | batch 4 loss: 0.00248353788629\n",
      "epoch 52 | batch 5 loss: 0.00220821611583\n",
      "epoch 52 | batch 6 loss: 0.00360512267798\n",
      "epoch 52 | batch 7 loss: 0.00233206804842\n",
      "epoch 52 | batch 8 loss: 0.00236987438984\n",
      "epoch 52 | batch 9 loss: 0.00243510399014\n",
      "epoch 52 | batch 10 loss: 0.00235270778649\n",
      "epoch 52 | batch 11 loss: 0.00203038495965\n",
      "epoch 52 | batch 12 loss: 0.00234409421682\n",
      "epoch 52 | batch 13 loss: 0.00233885645866\n",
      "epoch 52 | batch 14 loss: 0.00215995917097\n",
      "epoch 52 | batch 15 loss: 0.00257100514136\n",
      "epoch 52 | batch 16 loss: 0.00248692324385\n",
      "epoch 52 | batch 17 loss: 0.00272109219804\n",
      "epoch 52 | batch 18 loss: 0.0033252874855\n",
      "epoch 52 | batch 19 loss: 0.00293093174696\n",
      "epoch 52 | batch 20 loss: 0.00235818815418\n",
      "epoch 53 | batch 1 loss: 0.00227134535089\n",
      "epoch 53 | batch 2 loss: 0.00245029269718\n",
      "epoch 53 | batch 3 loss: 0.00292227999307\n",
      "epoch 53 | batch 4 loss: 0.00179354671855\n",
      "epoch 53 | batch 5 loss: 0.002180241514\n",
      "epoch 53 | batch 6 loss: 0.00239332695492\n",
      "epoch 53 | batch 7 loss: 0.00291044800542\n",
      "epoch 53 | batch 8 loss: 0.00235413294286\n",
      "epoch 53 | batch 9 loss: 0.00360307912342\n",
      "epoch 53 | batch 10 loss: 0.00256786542013\n",
      "epoch 53 | batch 11 loss: 0.0024610646069\n",
      "epoch 53 | batch 12 loss: 0.00193441356532\n",
      "epoch 53 | batch 13 loss: 0.0021790007595\n",
      "epoch 53 | batch 14 loss: 0.00225574127398\n",
      "epoch 53 | batch 15 loss: 0.00260466779582\n",
      "epoch 53 | batch 16 loss: 0.00204368284903\n",
      "epoch 53 | batch 17 loss: 0.00218210974708\n",
      "epoch 53 | batch 18 loss: 0.00318131386302\n",
      "epoch 53 | batch 19 loss: 0.00241721328348\n",
      "epoch 53 | batch 20 loss: 0.00292243133299\n",
      "epoch 54 | batch 1 loss: 0.00178631907329\n",
      "epoch 54 | batch 2 loss: 0.00232227775268\n",
      "epoch 54 | batch 3 loss: 0.00265386211686\n",
      "epoch 54 | batch 4 loss: 0.00194571807515\n",
      "epoch 54 | batch 5 loss: 0.00230254721828\n",
      "epoch 54 | batch 6 loss: 0.00214538839646\n",
      "epoch 54 | batch 7 loss: 0.0022893184796\n",
      "epoch 54 | batch 8 loss: 0.00295774941333\n",
      "epoch 54 | batch 9 loss: 0.00246074283496\n",
      "epoch 54 | batch 10 loss: 0.00217491132207\n",
      "epoch 54 | batch 11 loss: 0.0021734838374\n",
      "epoch 54 | batch 12 loss: 0.00240792776458\n",
      "epoch 54 | batch 13 loss: 0.0022283506114\n",
      "epoch 54 | batch 14 loss: 0.00359993893653\n",
      "epoch 54 | batch 15 loss: 0.00225251470692\n",
      "epoch 54 | batch 16 loss: 0.00204380298965\n",
      "epoch 54 | batch 17 loss: 0.0032044290565\n",
      "epoch 54 | batch 18 loss: 0.00262384815142\n",
      "epoch 54 | batch 19 loss: 0.0021574893035\n",
      "epoch 54 | batch 20 loss: 0.00187743839342\n",
      "epoch 55 | batch 1 loss: 0.00171865976881\n",
      "epoch 55 | batch 2 loss: 0.0023808197584\n",
      "epoch 55 | batch 3 loss: 0.00294061750174\n",
      "epoch 55 | batch 4 loss: 0.00209384039044\n",
      "epoch 55 | batch 5 loss: 0.00246437778696\n",
      "epoch 55 | batch 6 loss: 0.00195411476307\n",
      "epoch 55 | batch 7 loss: 0.00242036650889\n",
      "epoch 55 | batch 8 loss: 0.00307989912108\n",
      "epoch 55 | batch 9 loss: 0.00256493897177\n",
      "epoch 55 | batch 10 loss: 0.00194878480397\n",
      "epoch 55 | batch 11 loss: 0.0024960518349\n",
      "epoch 55 | batch 12 loss: 0.00187088048551\n",
      "epoch 55 | batch 13 loss: 0.00202239188366\n",
      "epoch 55 | batch 14 loss: 0.00198878836818\n",
      "epoch 55 | batch 15 loss: 0.00219828356057\n",
      "epoch 55 | batch 16 loss: 0.0028004811611\n",
      "epoch 55 | batch 17 loss: 0.0019632014446\n",
      "epoch 55 | batch 18 loss: 0.00198443210684\n",
      "epoch 55 | batch 19 loss: 0.00229158159345\n",
      "epoch 55 | batch 20 loss: 0.00270396540873\n",
      "epoch 56 | batch 1 loss: 0.00236846855842\n",
      "epoch 56 | batch 2 loss: 0.00260748039\n",
      "epoch 56 | batch 3 loss: 0.00261698663235\n",
      "epoch 56 | batch 4 loss: 0.00187382439617\n",
      "epoch 56 | batch 5 loss: 0.00285463011824\n",
      "epoch 56 | batch 6 loss: 0.00256172125228\n",
      "epoch 56 | batch 7 loss: 0.00169979885686\n",
      "epoch 56 | batch 8 loss: 0.00287956302054\n",
      "epoch 56 | batch 9 loss: 0.00245157442987\n",
      "epoch 56 | batch 10 loss: 0.00202665943652\n",
      "epoch 56 | batch 11 loss: 0.0020414206665\n",
      "epoch 56 | batch 12 loss: 0.00192497496027\n",
      "epoch 56 | batch 13 loss: 0.0021909205243\n",
      "epoch 56 | batch 14 loss: 0.00165099557489\n",
      "epoch 56 | batch 15 loss: 0.00200768047944\n",
      "epoch 56 | batch 16 loss: 0.0018467081245\n",
      "epoch 56 | batch 17 loss: 0.00217019487172\n",
      "epoch 56 | batch 18 loss: 0.00221710721962\n",
      "epoch 56 | batch 19 loss: 0.0021846096497\n",
      "epoch 56 | batch 20 loss: 0.0021861619316\n",
      "epoch 57 | batch 1 loss: 0.00248544034548\n",
      "epoch 57 | batch 2 loss: 0.00186459952965\n",
      "epoch 57 | batch 3 loss: 0.00192721339408\n",
      "epoch 57 | batch 4 loss: 0.00271458853967\n",
      "epoch 57 | batch 5 loss: 0.00178834947292\n",
      "epoch 57 | batch 6 loss: 0.00210873619653\n",
      "epoch 57 | batch 7 loss: 0.00243934360333\n",
      "epoch 57 | batch 8 loss: 0.00164979614783\n",
      "epoch 57 | batch 9 loss: 0.00215308088809\n",
      "epoch 57 | batch 10 loss: 0.00214917049743\n",
      "epoch 57 | batch 11 loss: 0.00220080884174\n",
      "epoch 57 | batch 12 loss: 0.00248371018097\n",
      "epoch 57 | batch 13 loss: 0.00217324774712\n",
      "epoch 57 | batch 14 loss: 0.00189105968457\n",
      "epoch 57 | batch 15 loss: 0.0023758513853\n",
      "epoch 57 | batch 16 loss: 0.0018924738979\n",
      "epoch 57 | batch 17 loss: 0.00193082820624\n",
      "epoch 57 | batch 18 loss: 0.00206175050698\n",
      "epoch 57 | batch 19 loss: 0.00189545191824\n",
      "epoch 57 | batch 20 loss: 0.00253284350038\n",
      "epoch 58 | batch 1 loss: 0.00203291210346\n",
      "epoch 58 | batch 2 loss: 0.00254964455962\n",
      "epoch 58 | batch 3 loss: 0.00210725259967\n",
      "epoch 58 | batch 4 loss: 0.00253839278594\n",
      "epoch 58 | batch 5 loss: 0.00198295712471\n",
      "epoch 58 | batch 6 loss: 0.00169990048744\n",
      "epoch 58 | batch 7 loss: 0.00192236760631\n",
      "epoch 58 | batch 8 loss: 0.00237712776288\n",
      "epoch 58 | batch 9 loss: 0.00190168700647\n",
      "epoch 58 | batch 10 loss: 0.00208176625893\n",
      "epoch 58 | batch 11 loss: 0.00264052301645\n",
      "epoch 58 | batch 12 loss: 0.00166077632457\n",
      "epoch 58 | batch 13 loss: 0.00209990539588\n",
      "epoch 58 | batch 14 loss: 0.00195303792134\n",
      "epoch 58 | batch 15 loss: 0.00195850385353\n",
      "epoch 58 | batch 16 loss: 0.00186194642447\n",
      "epoch 58 | batch 17 loss: 0.00197804789059\n",
      "epoch 58 | batch 18 loss: 0.00207507889718\n",
      "epoch 58 | batch 19 loss: 0.00165060441941\n",
      "epoch 58 | batch 20 loss: 0.00212552491575\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in xrange(58):\n",
    "    for step, (batch_imgs, batch_labels) in enumerate(loader):\n",
    "        y_pred = net(batch_imgs)\n",
    "        loss = loss_function(y_pred, batch_labels)\n",
    "        \n",
    "        #更新参数\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print 'epoch {} | batch {} loss: {}'.format(epoch+1, step+1, loss.data.item())\n",
    "\n",
    "#保存模型(参数)\n",
    "torch.save(net.state_dict(), 'mnist_3LayersNet_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9738\n"
     ]
    }
   ],
   "source": [
    "#加载训练好的模型\n",
    "net.load_state_dict(torch.load('mnist_3LayersNet_model.pkl'))\n",
    "\n",
    "#test\n",
    "\n",
    "test_set = load_mnist('t10k')\n",
    "origin = test_set['images']\n",
    "test_imgs = torch.from_numpy(test_set['images']).type(torch.float)\n",
    "test_labels = torch.from_numpy(test_set['labels']).type(torch.long)\n",
    "\n",
    "test_vec_imgs = test_imgs.reshape(test_imgs.shape[0], -1)\n",
    "test_vec_imgs -= torch.mean(test_vec_imgs, dim=0)\n",
    "\n",
    "top_k = 1\n",
    "acc = 0\n",
    "y_pred = net(test_vec_imgs)\n",
    "ss, indices = torch.sort(y_pred, dim=1, descending=True)\n",
    "results = indices[:,0:top_k]\n",
    "for idx, label in enumerate(test_labels):\n",
    "    if label in results[idx]:\n",
    "        acc += 1\n",
    "print 'accuracy: {}'.format(float(acc)/test_labels.shape[0])\n",
    "# for idx in xrange(10000):\n",
    "#     plt.subplot(2,1,1)\n",
    "#     plt.imshow(origin[idx], cmap='Greys')\n",
    "#     plt.subplot(2,1,2)\n",
    "#     plt.barh(range(y_pred.shape[1]), y_pred[idx].data.numpy(), color='blue')\n",
    "#     plt.yticks(range(y_pred.shape[1]), range(y_pred.shape[1]))\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
