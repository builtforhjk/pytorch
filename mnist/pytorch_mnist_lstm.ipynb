{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "from FileReader import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "train_set = load_mnist('train')\n",
    "train_imgs = torch.from_numpy(train_set['images']).type(torch.float)\n",
    "train_labels = torch.from_numpy(train_set['labels']).type(torch.long)\n",
    "print(train_imgs.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_num = train_imgs.shape[0]\n",
    "BATCH_SIZE = int(train_imgs_num * 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Data.TensorDataset(train_imgs, train_labels)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyLSTM(\n",
      "  (LSTM): LSTM(28, 64, batch_first=True)\n",
      "  (outLayer): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, in_feature):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        \n",
    "        self.LSTM = nn.LSTM(\n",
    "            input_size=in_feature,\n",
    "            hidden_size=64,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "        self.outLayer = nn.Linear(in_features=64, out_features=10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        '''\n",
    "        x shape[batch_size, time_step, input_size]\n",
    "        \n",
    "        '''\n",
    "        r_out, (h_n,h_c) = self.LSTM(x,None)\n",
    "        score = self.outLayer(r_out[:,-1,:])\n",
    "        return score\n",
    "\n",
    "\n",
    "model = MyLSTM(28)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 1 loss: 2.30822682381\n",
      "epoch 1 step 2 loss: 2.21908259392\n",
      "epoch 1 step 3 loss: 2.12824487686\n",
      "epoch 1 step 4 loss: 2.00662589073\n",
      "epoch 1 step 5 loss: 1.85864579678\n",
      "epoch 1 step 6 loss: 1.7079886198\n",
      "epoch 1 step 7 loss: 1.53588056564\n",
      "epoch 1 step 8 loss: 1.42300570011\n",
      "epoch 1 step 9 loss: 1.26240897179\n",
      "epoch 1 step 10 loss: 1.17355144024\n",
      "epoch 1 step 11 loss: 1.04684782028\n",
      "epoch 1 step 12 loss: 1.00597512722\n",
      "epoch 1 step 13 loss: 0.958687245846\n",
      "epoch 1 step 14 loss: 0.896046876907\n",
      "epoch 1 step 15 loss: 0.863631188869\n",
      "epoch 1 step 16 loss: 0.80866932869\n",
      "epoch 1 step 17 loss: 0.733355224133\n",
      "epoch 1 step 18 loss: 0.741290688515\n",
      "epoch 1 step 19 loss: 0.692173719406\n",
      "epoch 1 step 20 loss: 0.713667452335\n",
      "epoch 2 step 1 loss: 0.622769355774\n",
      "epoch 2 step 2 loss: 0.657671332359\n",
      "epoch 2 step 3 loss: 0.59661090374\n",
      "epoch 2 step 4 loss: 0.598862886429\n",
      "epoch 2 step 5 loss: 0.593277812004\n",
      "epoch 2 step 6 loss: 0.561823010445\n",
      "epoch 2 step 7 loss: 0.52242577076\n",
      "epoch 2 step 8 loss: 0.533000051975\n",
      "epoch 2 step 9 loss: 0.526711940765\n",
      "epoch 2 step 10 loss: 0.544269025326\n",
      "epoch 2 step 11 loss: 0.492715299129\n",
      "epoch 2 step 12 loss: 0.489436835051\n",
      "epoch 2 step 13 loss: 0.513087332249\n",
      "epoch 2 step 14 loss: 0.497197508812\n",
      "epoch 2 step 15 loss: 0.490707308054\n",
      "epoch 2 step 16 loss: 0.491407036781\n",
      "epoch 2 step 17 loss: 0.495178431273\n",
      "epoch 2 step 18 loss: 0.472223907709\n",
      "epoch 2 step 19 loss: 0.47469368577\n",
      "epoch 2 step 20 loss: 0.489828705788\n",
      "epoch 3 step 1 loss: 0.435591757298\n",
      "epoch 3 step 2 loss: 0.445703566074\n",
      "epoch 3 step 3 loss: 0.443923413754\n",
      "epoch 3 step 4 loss: 0.457215726376\n",
      "epoch 3 step 5 loss: 0.426370024681\n",
      "epoch 3 step 6 loss: 0.411629587412\n",
      "epoch 3 step 7 loss: 0.415019333363\n",
      "epoch 3 step 8 loss: 0.43637740612\n",
      "epoch 3 step 9 loss: 0.426643431187\n",
      "epoch 3 step 10 loss: 0.401667267084\n",
      "epoch 3 step 11 loss: 0.361273795366\n",
      "epoch 3 step 12 loss: 0.396797537804\n",
      "epoch 3 step 13 loss: 0.393363237381\n",
      "epoch 3 step 14 loss: 0.384749054909\n",
      "epoch 3 step 15 loss: 0.39202645421\n",
      "epoch 3 step 16 loss: 0.379791349173\n",
      "epoch 3 step 17 loss: 0.379350841045\n",
      "epoch 3 step 18 loss: 0.393952101469\n",
      "epoch 3 step 19 loss: 0.366532504559\n",
      "epoch 3 step 20 loss: 0.399264276028\n",
      "epoch 4 step 1 loss: 0.350027918816\n",
      "epoch 4 step 2 loss: 0.388604968786\n",
      "epoch 4 step 3 loss: 0.353288948536\n",
      "epoch 4 step 4 loss: 0.370972663164\n",
      "epoch 4 step 5 loss: 0.390556365252\n",
      "epoch 4 step 6 loss: 0.347181260586\n",
      "epoch 4 step 7 loss: 0.359466433525\n",
      "epoch 4 step 8 loss: 0.365410774946\n",
      "epoch 4 step 9 loss: 0.358765214682\n",
      "epoch 4 step 10 loss: 0.373249232769\n",
      "epoch 4 step 11 loss: 0.348065763712\n",
      "epoch 4 step 12 loss: 0.358592152596\n",
      "epoch 4 step 13 loss: 0.37455201149\n",
      "epoch 4 step 14 loss: 0.373061537743\n",
      "epoch 4 step 15 loss: 0.349292755127\n",
      "epoch 4 step 16 loss: 0.360498487949\n",
      "epoch 4 step 17 loss: 0.334293365479\n",
      "epoch 4 step 18 loss: 0.322511672974\n",
      "epoch 4 step 19 loss: 0.346845537424\n",
      "epoch 4 step 20 loss: 0.333347827196\n",
      "epoch 5 step 1 loss: 0.353813022375\n",
      "epoch 5 step 2 loss: 0.316072702408\n",
      "epoch 5 step 3 loss: 0.339840292931\n",
      "epoch 5 step 4 loss: 0.305739820004\n",
      "epoch 5 step 5 loss: 0.339765310287\n",
      "epoch 5 step 6 loss: 0.335966527462\n",
      "epoch 5 step 7 loss: 0.353944063187\n",
      "epoch 5 step 8 loss: 0.337084025145\n",
      "epoch 5 step 9 loss: 0.30941593647\n",
      "epoch 5 step 10 loss: 0.319736242294\n",
      "epoch 5 step 11 loss: 0.327236235142\n",
      "epoch 5 step 12 loss: 0.349971801043\n",
      "epoch 5 step 13 loss: 0.325282305479\n",
      "epoch 5 step 14 loss: 0.3039265275\n",
      "epoch 5 step 15 loss: 0.309955656528\n",
      "epoch 5 step 16 loss: 0.310486525297\n",
      "epoch 5 step 17 loss: 0.313743025064\n",
      "epoch 5 step 18 loss: 0.319056481123\n",
      "epoch 5 step 19 loss: 0.317354381084\n",
      "epoch 5 step 20 loss: 0.327747672796\n",
      "epoch 6 step 1 loss: 0.302634626627\n",
      "epoch 6 step 2 loss: 0.293442457914\n",
      "epoch 6 step 3 loss: 0.28371077776\n",
      "epoch 6 step 4 loss: 0.291506618261\n",
      "epoch 6 step 5 loss: 0.309664934874\n",
      "epoch 6 step 6 loss: 0.309871405363\n",
      "epoch 6 step 7 loss: 0.297525376081\n",
      "epoch 6 step 8 loss: 0.298339784145\n",
      "epoch 6 step 9 loss: 0.301342517138\n",
      "epoch 6 step 10 loss: 0.307844042778\n",
      "epoch 6 step 11 loss: 0.302218228579\n",
      "epoch 6 step 12 loss: 0.289158582687\n",
      "epoch 6 step 13 loss: 0.307008236647\n",
      "epoch 6 step 14 loss: 0.307645976543\n",
      "epoch 6 step 15 loss: 0.32015222311\n",
      "epoch 6 step 16 loss: 0.284155994654\n",
      "epoch 6 step 17 loss: 0.310925960541\n",
      "epoch 6 step 18 loss: 0.292252093554\n",
      "epoch 6 step 19 loss: 0.284862428904\n",
      "epoch 6 step 20 loss: 0.283255308867\n",
      "epoch 7 step 1 loss: 0.283796280622\n",
      "epoch 7 step 2 loss: 0.290253549814\n",
      "epoch 7 step 3 loss: 0.281321138144\n",
      "epoch 7 step 4 loss: 0.288708984852\n",
      "epoch 7 step 5 loss: 0.28817242384\n",
      "epoch 7 step 6 loss: 0.264184594154\n",
      "epoch 7 step 7 loss: 0.302433341742\n",
      "epoch 7 step 8 loss: 0.280615895987\n",
      "epoch 7 step 9 loss: 0.27554371953\n",
      "epoch 7 step 10 loss: 0.276153147221\n",
      "epoch 7 step 11 loss: 0.289159357548\n",
      "epoch 7 step 12 loss: 0.301202833652\n",
      "epoch 7 step 13 loss: 0.30495005846\n",
      "epoch 7 step 14 loss: 0.266769766808\n",
      "epoch 7 step 15 loss: 0.281510591507\n",
      "epoch 7 step 16 loss: 0.243233948946\n",
      "epoch 7 step 17 loss: 0.27193287015\n",
      "epoch 7 step 18 loss: 0.259247213602\n",
      "epoch 7 step 19 loss: 0.276777923107\n",
      "epoch 7 step 20 loss: 0.274449467659\n",
      "epoch 8 step 1 loss: 0.266963899136\n",
      "epoch 8 step 2 loss: 0.260421454906\n",
      "epoch 8 step 3 loss: 0.261043548584\n",
      "epoch 8 step 4 loss: 0.260236531496\n",
      "epoch 8 step 5 loss: 0.243226155639\n",
      "epoch 8 step 6 loss: 0.255343198776\n",
      "epoch 8 step 7 loss: 0.264205217361\n",
      "epoch 8 step 8 loss: 0.249596148729\n",
      "epoch 8 step 9 loss: 0.290244936943\n",
      "epoch 8 step 10 loss: 0.26421636343\n",
      "epoch 8 step 11 loss: 0.27714189887\n",
      "epoch 8 step 12 loss: 0.272330880165\n",
      "epoch 8 step 13 loss: 0.278354823589\n",
      "epoch 8 step 14 loss: 0.26420673728\n",
      "epoch 8 step 15 loss: 0.261145055294\n",
      "epoch 8 step 16 loss: 0.267316043377\n",
      "epoch 8 step 17 loss: 0.253164231777\n",
      "epoch 8 step 18 loss: 0.259283721447\n",
      "epoch 8 step 19 loss: 0.281849771738\n",
      "epoch 8 step 20 loss: 0.256548881531\n",
      "epoch 9 step 1 loss: 0.237596571445\n",
      "epoch 9 step 2 loss: 0.259218215942\n",
      "epoch 9 step 3 loss: 0.26986142993\n",
      "epoch 9 step 4 loss: 0.25224301219\n",
      "epoch 9 step 5 loss: 0.253165006638\n",
      "epoch 9 step 6 loss: 0.259932875633\n",
      "epoch 9 step 7 loss: 0.234984561801\n",
      "epoch 9 step 8 loss: 0.266824662685\n",
      "epoch 9 step 9 loss: 0.246476113796\n",
      "epoch 9 step 10 loss: 0.260775357485\n",
      "epoch 9 step 11 loss: 0.241280734539\n",
      "epoch 9 step 12 loss: 0.253907442093\n",
      "epoch 9 step 13 loss: 0.25100466609\n",
      "epoch 9 step 14 loss: 0.254928410053\n",
      "epoch 9 step 15 loss: 0.250058174133\n",
      "epoch 9 step 16 loss: 0.247945293784\n",
      "epoch 9 step 17 loss: 0.235018596053\n",
      "epoch 9 step 18 loss: 0.265950798988\n",
      "epoch 9 step 19 loss: 0.221359074116\n",
      "epoch 9 step 20 loss: 0.25463873148\n",
      "epoch 10 step 1 loss: 0.241048812866\n",
      "epoch 10 step 2 loss: 0.23583085835\n",
      "epoch 10 step 3 loss: 0.231729224324\n",
      "epoch 10 step 4 loss: 0.231456235051\n",
      "epoch 10 step 5 loss: 0.252073973417\n",
      "epoch 10 step 6 loss: 0.243545532227\n",
      "epoch 10 step 7 loss: 0.23822684586\n",
      "epoch 10 step 8 loss: 0.237039610744\n",
      "epoch 10 step 9 loss: 0.214296221733\n",
      "epoch 10 step 10 loss: 0.247090399265\n",
      "epoch 10 step 11 loss: 0.233620539308\n",
      "epoch 10 step 12 loss: 0.237972691655\n",
      "epoch 10 step 13 loss: 0.221625819802\n",
      "epoch 10 step 14 loss: 0.240165784955\n",
      "epoch 10 step 15 loss: 0.252832949162\n",
      "epoch 10 step 16 loss: 0.266378879547\n",
      "epoch 10 step 17 loss: 0.254891842604\n",
      "epoch 10 step 18 loss: 0.219491451979\n",
      "epoch 10 step 19 loss: 0.236802443862\n",
      "epoch 10 step 20 loss: 0.250654101372\n",
      "epoch 11 step 1 loss: 0.219633743167\n",
      "epoch 11 step 2 loss: 0.247305765748\n",
      "epoch 11 step 3 loss: 0.217417150736\n",
      "epoch 11 step 4 loss: 0.214592531323\n",
      "epoch 11 step 5 loss: 0.229411140084\n",
      "epoch 11 step 6 loss: 0.241718500853\n",
      "epoch 11 step 7 loss: 0.226829826832\n",
      "epoch 11 step 8 loss: 0.220092833042\n",
      "epoch 11 step 9 loss: 0.22804325819\n",
      "epoch 11 step 10 loss: 0.239751234651\n",
      "epoch 11 step 11 loss: 0.246081829071\n",
      "epoch 11 step 12 loss: 0.217222079635\n",
      "epoch 11 step 13 loss: 0.242489397526\n",
      "epoch 11 step 14 loss: 0.256291568279\n",
      "epoch 11 step 15 loss: 0.23829691112\n",
      "epoch 11 step 16 loss: 0.250922560692\n",
      "epoch 11 step 17 loss: 0.228598788381\n",
      "epoch 11 step 18 loss: 0.234264567494\n",
      "epoch 11 step 19 loss: 0.221809983253\n",
      "epoch 11 step 20 loss: 0.217217251658\n",
      "epoch 12 step 1 loss: 0.222769901156\n",
      "epoch 12 step 2 loss: 0.231958433986\n",
      "epoch 12 step 3 loss: 0.22087392211\n",
      "epoch 12 step 4 loss: 0.219633772969\n",
      "epoch 12 step 5 loss: 0.212429255247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 step 6 loss: 0.20428314805\n",
      "epoch 12 step 7 loss: 0.235816687346\n",
      "epoch 12 step 8 loss: 0.214053735137\n",
      "epoch 12 step 9 loss: 0.238327622414\n",
      "epoch 12 step 10 loss: 0.237817913294\n",
      "epoch 12 step 11 loss: 0.225238546729\n",
      "epoch 12 step 12 loss: 0.21083265543\n",
      "epoch 12 step 13 loss: 0.242616146803\n",
      "epoch 12 step 14 loss: 0.230630844831\n",
      "epoch 12 step 15 loss: 0.219717651606\n",
      "epoch 12 step 16 loss: 0.237961798906\n",
      "epoch 12 step 17 loss: 0.220001995564\n",
      "epoch 12 step 18 loss: 0.227932557464\n",
      "epoch 12 step 19 loss: 0.231584817171\n",
      "epoch 12 step 20 loss: 0.225674852729\n",
      "epoch 13 step 1 loss: 0.213577210903\n",
      "epoch 13 step 2 loss: 0.229484215379\n",
      "epoch 13 step 3 loss: 0.206876382232\n",
      "epoch 13 step 4 loss: 0.220386072993\n",
      "epoch 13 step 5 loss: 0.217208713293\n",
      "epoch 13 step 6 loss: 0.223251014948\n",
      "epoch 13 step 7 loss: 0.210183545947\n",
      "epoch 13 step 8 loss: 0.229777023196\n",
      "epoch 13 step 9 loss: 0.202382072806\n",
      "epoch 13 step 10 loss: 0.222196772695\n",
      "epoch 13 step 11 loss: 0.221987262368\n",
      "epoch 13 step 12 loss: 0.217649072409\n",
      "epoch 13 step 13 loss: 0.217159628868\n",
      "epoch 13 step 14 loss: 0.221162542701\n",
      "epoch 13 step 15 loss: 0.215887904167\n",
      "epoch 13 step 16 loss: 0.226700216532\n",
      "epoch 13 step 17 loss: 0.240756809711\n",
      "epoch 13 step 18 loss: 0.223016187549\n",
      "epoch 13 step 19 loss: 0.225574478507\n",
      "epoch 13 step 20 loss: 0.224359214306\n",
      "epoch 14 step 1 loss: 0.213167518377\n",
      "epoch 14 step 2 loss: 0.208978787065\n",
      "epoch 14 step 3 loss: 0.196917280555\n",
      "epoch 14 step 4 loss: 0.203473493457\n",
      "epoch 14 step 5 loss: 0.21579220891\n",
      "epoch 14 step 6 loss: 0.212750062346\n",
      "epoch 14 step 7 loss: 0.22961486876\n",
      "epoch 14 step 8 loss: 0.223297774792\n",
      "epoch 14 step 9 loss: 0.193541660905\n",
      "epoch 14 step 10 loss: 0.224195450544\n",
      "epoch 14 step 11 loss: 0.222725853324\n",
      "epoch 14 step 12 loss: 0.236609965563\n",
      "epoch 14 step 13 loss: 0.232028827071\n",
      "epoch 14 step 14 loss: 0.236609309912\n",
      "epoch 14 step 15 loss: 0.217212021351\n",
      "epoch 14 step 16 loss: 0.237772643566\n",
      "epoch 14 step 17 loss: 0.210397914052\n",
      "epoch 14 step 18 loss: 0.195979252458\n",
      "epoch 14 step 19 loss: 0.215650781989\n",
      "epoch 14 step 20 loss: 0.221105471253\n",
      "epoch 15 step 1 loss: 0.201357886195\n",
      "epoch 15 step 2 loss: 0.210146084428\n",
      "epoch 15 step 3 loss: 0.213454440236\n",
      "epoch 15 step 4 loss: 0.216248065233\n",
      "epoch 15 step 5 loss: 0.200812831521\n",
      "epoch 15 step 6 loss: 0.223710760474\n",
      "epoch 15 step 7 loss: 0.205771848559\n",
      "epoch 15 step 8 loss: 0.197952792048\n",
      "epoch 15 step 9 loss: 0.216144829988\n",
      "epoch 15 step 10 loss: 0.221662074327\n",
      "epoch 15 step 11 loss: 0.207288831472\n",
      "epoch 15 step 12 loss: 0.20654772222\n",
      "epoch 15 step 13 loss: 0.207663923502\n",
      "epoch 15 step 14 loss: 0.18837839365\n",
      "epoch 15 step 15 loss: 0.209439456463\n",
      "epoch 15 step 16 loss: 0.189967423677\n",
      "epoch 15 step 17 loss: 0.20787319541\n",
      "epoch 15 step 18 loss: 0.222796857357\n",
      "epoch 15 step 19 loss: 0.20589196682\n",
      "epoch 15 step 20 loss: 0.202899292111\n",
      "epoch 16 step 1 loss: 0.205625489354\n",
      "epoch 16 step 2 loss: 0.187405198812\n",
      "epoch 16 step 3 loss: 0.180685386062\n",
      "epoch 16 step 4 loss: 0.201393902302\n",
      "epoch 16 step 5 loss: 0.200474798679\n",
      "epoch 16 step 6 loss: 0.213423058391\n",
      "epoch 16 step 7 loss: 0.204539999366\n",
      "epoch 16 step 8 loss: 0.208579257131\n",
      "epoch 16 step 9 loss: 0.189277648926\n",
      "epoch 16 step 10 loss: 0.190905928612\n",
      "epoch 16 step 11 loss: 0.192577347159\n",
      "epoch 16 step 12 loss: 0.228617757559\n",
      "epoch 16 step 13 loss: 0.207739502192\n",
      "epoch 16 step 14 loss: 0.178239643574\n",
      "epoch 16 step 15 loss: 0.201518803835\n",
      "epoch 16 step 16 loss: 0.204345539212\n",
      "epoch 16 step 17 loss: 0.226117536426\n",
      "epoch 16 step 18 loss: 0.193370178342\n",
      "epoch 16 step 19 loss: 0.187781244516\n",
      "epoch 16 step 20 loss: 0.182158589363\n",
      "epoch 17 step 1 loss: 0.181246295571\n",
      "epoch 17 step 2 loss: 0.19252859056\n",
      "epoch 17 step 3 loss: 0.191380515695\n",
      "epoch 17 step 4 loss: 0.193341001868\n",
      "epoch 17 step 5 loss: 0.203686237335\n",
      "epoch 17 step 6 loss: 0.200472459197\n",
      "epoch 17 step 7 loss: 0.193879827857\n",
      "epoch 17 step 8 loss: 0.177616864443\n",
      "epoch 17 step 9 loss: 0.204177871346\n",
      "epoch 17 step 10 loss: 0.194412827492\n",
      "epoch 17 step 11 loss: 0.207523316145\n",
      "epoch 17 step 12 loss: 0.182493269444\n",
      "epoch 17 step 13 loss: 0.167334064841\n",
      "epoch 17 step 14 loss: 0.16858805716\n",
      "epoch 17 step 15 loss: 0.173040628433\n",
      "epoch 17 step 16 loss: 0.196635559201\n",
      "epoch 17 step 17 loss: 0.195746690035\n",
      "epoch 17 step 18 loss: 0.185884639621\n",
      "epoch 17 step 19 loss: 0.188928753138\n",
      "epoch 17 step 20 loss: 0.179851830006\n",
      "epoch 18 step 1 loss: 0.194606080651\n",
      "epoch 18 step 2 loss: 0.168698146939\n",
      "epoch 18 step 3 loss: 0.179344177246\n",
      "epoch 18 step 4 loss: 0.163223087788\n",
      "epoch 18 step 5 loss: 0.179826647043\n",
      "epoch 18 step 6 loss: 0.179226130247\n",
      "epoch 18 step 7 loss: 0.187719032168\n",
      "epoch 18 step 8 loss: 0.186724603176\n",
      "epoch 18 step 9 loss: 0.160802260041\n",
      "epoch 18 step 10 loss: 0.171544134617\n",
      "epoch 18 step 11 loss: 0.190731957555\n",
      "epoch 18 step 12 loss: 0.179469928145\n",
      "epoch 18 step 13 loss: 0.184326678514\n",
      "epoch 18 step 14 loss: 0.178378939629\n",
      "epoch 18 step 15 loss: 0.185779035091\n",
      "epoch 18 step 16 loss: 0.204055845737\n",
      "epoch 18 step 17 loss: 0.190314367414\n",
      "epoch 18 step 18 loss: 0.210017070174\n",
      "epoch 18 step 19 loss: 0.191424176097\n",
      "epoch 18 step 20 loss: 0.205398321152\n",
      "epoch 19 step 1 loss: 0.185408562422\n",
      "epoch 19 step 2 loss: 0.176116377115\n",
      "epoch 19 step 3 loss: 0.174926832318\n",
      "epoch 19 step 4 loss: 0.164112880826\n",
      "epoch 19 step 5 loss: 0.183638632298\n",
      "epoch 19 step 6 loss: 0.197053343058\n",
      "epoch 19 step 7 loss: 0.181660681963\n",
      "epoch 19 step 8 loss: 0.178560957313\n",
      "epoch 19 step 9 loss: 0.172485753894\n",
      "epoch 19 step 10 loss: 0.18627601862\n",
      "epoch 19 step 11 loss: 0.164304256439\n",
      "epoch 19 step 12 loss: 0.17232657969\n",
      "epoch 19 step 13 loss: 0.18514084816\n",
      "epoch 19 step 14 loss: 0.195494160056\n",
      "epoch 19 step 15 loss: 0.20414198935\n",
      "epoch 19 step 16 loss: 0.177705422044\n",
      "epoch 19 step 17 loss: 0.195403292775\n",
      "epoch 19 step 18 loss: 0.189502000809\n",
      "epoch 19 step 19 loss: 0.159432858229\n",
      "epoch 19 step 20 loss: 0.19703130424\n",
      "epoch 20 step 1 loss: 0.168540537357\n",
      "epoch 20 step 2 loss: 0.163566336036\n",
      "epoch 20 step 3 loss: 0.180414870381\n",
      "epoch 20 step 4 loss: 0.16944822669\n",
      "epoch 20 step 5 loss: 0.170055404305\n",
      "epoch 20 step 6 loss: 0.164621770382\n",
      "epoch 20 step 7 loss: 0.173386722803\n",
      "epoch 20 step 8 loss: 0.177524492145\n",
      "epoch 20 step 9 loss: 0.182138219476\n",
      "epoch 20 step 10 loss: 0.166720747948\n",
      "epoch 20 step 11 loss: 0.170718446374\n",
      "epoch 20 step 12 loss: 0.181269854307\n",
      "epoch 20 step 13 loss: 0.188309788704\n",
      "epoch 20 step 14 loss: 0.177156254649\n",
      "epoch 20 step 15 loss: 0.192571878433\n",
      "epoch 20 step 16 loss: 0.183678582311\n",
      "epoch 20 step 17 loss: 0.15634547174\n",
      "epoch 20 step 18 loss: 0.158776208758\n",
      "epoch 20 step 19 loss: 0.174247190356\n",
      "epoch 20 step 20 loss: 0.180257156491\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in xrange(20):\n",
    "    \n",
    "    for step, (batch_imgs, batch_labels) in enumerate(loader):\n",
    "        \n",
    "        y_pred = model(batch_imgs)\n",
    "        \n",
    "        loss = loss_func(y_pred, batch_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('epoch {} step {} loss: {}'.format(epoch+1, step+1, loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "test_set = load_mnist('t10k')\n",
    "test_imgs = torch.from_numpy(test_set['images']).type(torch.float)\n",
    "test_labels = torch.from_numpy(test_set['labels']).type(torch.long)\n",
    "print(test_imgs.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "score = model(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "pred = torch.max(score, dim=1)[1]\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9285\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx in xrange(10000):\n",
    "    accuracy += 1 if pred[idx] == test_labels[idx] else 0\n",
    "print('acc: {}'.format(float(accuracy)/10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mnist_lstm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
